<article><div class="l"><div class="gg gh gi gj gk gl gm ce gn ch l"></div><div class="l"><header class="pw-post-byline-header go gp gq gr gs gt gu gv gw gx l"><div class="o gy u"><div class="o"><div class="fj l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://oscar-defelice.medium.com/?source=post_page-----e9e0357525cc--------------------------------" rel="noopener follow"><div class="l do"><img alt="Oscar de Felice" class="l ch fl gz ha fp" height="48" loading="lazy" src="https://miro.medium.com/fit/c/96/96/0*xmSp_J_R-kJMTYPf.jpg" width="48"/><div class="fk fl l gz ha fo aq"></div></div></a></div><div class="l"><div class="pw-author bm b dm dn ga"><div class="hb o hc"><div><div aria-hidden="false" class="ci"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://oscar-defelice.medium.com/?source=post_page-----e9e0357525cc--------------------------------" rel="noopener follow">Oscar de Felice</a></div></div><div class="hd he hf hg hh d"><span><a class="bm b hi bo hj hk hl hm hn ho hp bd bz hq hr hs cd cf cg ch ci cj" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5b4c877fa451&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-design-to-deploy-the-whole-lifepath-of-a-machine-learning-app-e9e0357525cc&amp;user=Oscar+de+Felice&amp;userId=5b4c877fa451&amp;source=post_page-5b4c877fa451----e9e0357525cc---------------------follow_byline-----------" rel="noopener follow">Follow</a></span></div></div></div><div class="o ao ht"><p class="pw-published-date bm b bn bo cn"><span>Mar 18, 2021</span></p><div aria-hidden="true" class="hu ci"><span aria-hidden="true" class="l"><span class="bm b bn bo cn">Â·</span></span></div><div class="pw-reading-time bm b bn bo cn">26 min read</div></div></div></div><div class="o ao"><div class="h k hv hw hx"><div class="hy l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on twitter" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hy l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on facebook" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hy l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on linkedin" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l fr"><div><div aria-hidden="false" class="ci"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8" fill-rule="evenodd"></path></svg></span></button></div></div></div><div class="ib o ao"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe9e0357525cc&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-design-to-deploy-the-whole-lifepath-of-a-machine-learning-app-e9e0357525cc&amp;source=--------------------------bookmark_header-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="au de aw ax ay az ba hz bc id ie if ig"><svg aria-label="Add to list bookmark button" class="ic" fill="none" height="25" viewbox="0 0 25 25" width="25"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></button></a></span></div></div><div class="ck ih"><div><div aria-hidden="false" class="ci"></div></div></div></div></div><div class="ii ij ik j i d"><div class="fj l"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe9e0357525cc&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-design-to-deploy-the-whole-lifepath-of-a-machine-learning-app-e9e0357525cc&amp;source=--------------------------bookmark_header-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="au de aw il ay az ba im bc id cd o ao in io ig"><svg aria-label="Add to list bookmark button" class="ic" fill="none" height="25" viewbox="0 0 25 25" width="25"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg><p class="bm b bn bo cn">Save</p></button></a></span></div><div class="ip l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on twitter" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ip l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on facebook" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ip l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on linkedin" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l fr"><div><div aria-hidden="false" class="ci"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></header><span class="l"></span><section><div><div class="fo as iv iw ix iy"></div><div class="iz ja jb jc jd"><div class=""><h1 class="pw-post-title je jf jg bm jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ga" id="ba51">From Design to Deploy: The whole Lifepath of a Machine Learning app</h1></div><div class=""><h2 class="pw-subtitle-paragraph kd jf jg bm b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku cn" id="1f96">The step-by-step description to design, develop, deploy and maintain a Machine Learning application. Through an example. With code.</h2></div><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="cbe3">Why should you read a 25min reading time medium post? Well, here I tried to condense the complete path of a machine learning project, from data analysis to deployment on AWS EC2.</p><h1 class="lr ls jg bm lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi ga" id="4378">Introduction</h1><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="7411">In the age of innocence, after following our first ML courses, we all thought that to be a data scientist, working on notebooks would have been enough.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="bc5f">Once we left kindergarten, we learnt that this is far from the truth.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="9d11">Nowadays there is plenty of other skills a data scientist must have other than knowledge of machine learning algorithms (or more often library usage).</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="8c30">This post aims to go through an example (I will keep it easy on the model part) of a complete machine learning task example from design to deploy and maintain.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="8d8b">I do this because I have spoken and worked with dozens of data scientists, also not so junior in their career, and I got a picture of great confusion about the role. Data science is a great activity, but often data scientist codes are really difficult to bring in production (and even to read) because they have been written without thinking of the real-world use of the model. <br/>I find this is a matter of respect â for the whole stack of poor devils working on the model after the data scientist â provide a solid and simple model deploy.<br/>Furthermore, these days docker is a skill highly requested in all data science job offers, so why not take some time to see how dockerise a machine learning application?</p><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm mo"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/0*mC9AAF7LRih775yB.png 640w, https://miro.medium.com/max/720/0*mC9AAF7LRih775yB.png 720w, https://miro.medium.com/max/750/0*mC9AAF7LRih775yB.png 750w, https://miro.medium.com/max/786/0*mC9AAF7LRih775yB.png 786w, https://miro.medium.com/max/828/0*mC9AAF7LRih775yB.png 828w, https://miro.medium.com/max/1100/0*mC9AAF7LRih775yB.png 1100w, https://miro.medium.com/max/1400/0*mC9AAF7LRih775yB.png 1400w"/><img alt="" class="ce my mz c" height="449" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="na bl gn gl gm nb nc bm b bn bo cn">The ubiquitous image used to illustrate the machine learning project lifecycle. Image by [<a class="au nd" href="https://www.jeremyjordan.me/ml-projects-guide/" rel="noopener ugc nofollow" target="_blank">https://www.jeremyjordan.me/ml-projects-guide/</a>]</figcaption></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="9e32">The figure above is nice, but I think it may appear a bit too abstract. I will use my poor drawing abilities to redesign it as follows.</p><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm ne"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*f0FRKMNhiAdphyKvaL218g.png 640w, https://miro.medium.com/max/720/1*f0FRKMNhiAdphyKvaL218g.png 720w, https://miro.medium.com/max/750/1*f0FRKMNhiAdphyKvaL218g.png 750w, https://miro.medium.com/max/786/1*f0FRKMNhiAdphyKvaL218g.png 786w, https://miro.medium.com/max/828/1*f0FRKMNhiAdphyKvaL218g.png 828w, https://miro.medium.com/max/1100/1*f0FRKMNhiAdphyKvaL218g.png 1100w, https://miro.medium.com/max/1400/1*f0FRKMNhiAdphyKvaL218g.png 1400w"/><img alt="" class="ce my mz c" height="411" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="na bl gn gl gm nb nc bm b bn bo cn">A simplified model lifecycle. Image poorly drawn by the author.</figcaption></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="e751">The image above is also the schema we are going to follow in this post.</p><h1 class="lr ls jg bm lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi ga" id="a38a">Problem definition</h1><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="0341">To be concrete, letâs start by defining our problem. Imagine you work in a consulting company (as I do) and your colleague from sales comes to you saying âHey dude, an estate agency wants a house price estimator, can we do that?â.<br/>I hope your answer would be âno problemâ, hence we can start.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="4d28">Before diving into the problem, let me make an observation. There should be an earlier (and important) step: data collection (that can be scraping, client database interrogation, etc.), that will be neglected here because this would lead us out of track.</p></div><div class="o dx nf ng ii nh" role="separator"><span class="ni fl ci nj nk nl"></span><span class="ni fl ci nj nk nl"></span><span class="ni fl ci nj nk"></span></div><div class="iz ja jb jc jd"><h1 class="lr ls jg bm lt lu nm lw lx ly nn ma mb km no kn md kp np kq mf ks nq kt mh mi ga" id="803b">0. Preliminary analysis</h1><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="b3c0">Under this part normally goes data collection, labelling, data analysis, some visualisation to better understand the kind of problem we are dealing with, data cleaning, etc.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="3496">Since these procedures are heavily influenced by the specific data to cope with, we keep it as simple as possible. We will briefly describe exploratory data analysis and thatâs it.</p><h2 class="nr ls jg bm lt ns nt nu lx nv nw nx mb le ny nz md li oa ob mf lm oc od mh oe ga" id="a676">Data Collection</h2><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="0f45">I know, I wrote I would have neglected this part. I did not lie.<br/>Here I imagine, the client gave us a nicely labelled dataset (this <a class="au nd" href="https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html" rel="noopener ugc nofollow" target="_blank">one</a>). In real (tough) life you usually spend a lot of time labelling data yourself, but we are still living in fairy tales for now.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="91bd">Hence, letâs start by simply import our data into a pandas dataframe.</p><figure class="mp mq mr ms gx mt"><div class="m fs l do"><div class="of og l"></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="31f8">The <code class="fp oh oi oj ok b">print(df.head())</code> command prints the following</p><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm ol"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*BUff5V-nJY-EetK-MV-9Mw.png 640w, https://miro.medium.com/max/720/1*BUff5V-nJY-EetK-MV-9Mw.png 720w, https://miro.medium.com/max/750/1*BUff5V-nJY-EetK-MV-9Mw.png 750w, https://miro.medium.com/max/786/1*BUff5V-nJY-EetK-MV-9Mw.png 786w, https://miro.medium.com/max/828/1*BUff5V-nJY-EetK-MV-9Mw.png 828w, https://miro.medium.com/max/1100/1*BUff5V-nJY-EetK-MV-9Mw.png 1100w, https://miro.medium.com/max/1400/1*BUff5V-nJY-EetK-MV-9Mw.png 1400w"/><img alt="" class="ce my mz c" height="189" loading="lazy" role="presentation" width="700"/></picture></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="35df">One can look at print the quantity <code class="fp oh oi oj ok b">boston_dataset.DESCR</code> to have a brief description of the features.</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="0fa8"><strong class="ok jh">CRIM</strong>: Per capita crime rate by town<br/><strong class="ok jh">ZN</strong>: Proportion of residential land zoned for lots over 25,000 sq. ft<br/><strong class="ok jh">INDUS</strong>: Proportion of non-retail business acres per town<br/><strong class="ok jh">CHAS</strong>: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)<br/><strong class="ok jh">NOX</strong>: Nitric oxide concentration (parts per 10 million)<br/><strong class="ok jh">RM</strong>: Average number of rooms per dwelling<br/><strong class="ok jh">AGE</strong>: Proportion of owner-occupied units built prior to 1940<br/><strong class="ok jh">DIS</strong>: Weighted distances to five Boston employment centers<br/><strong class="ok jh">RAD</strong>: Index of accessibility to radial highways<br/><strong class="ok jh">TAX</strong>: Full-value property tax rate per $10,000<br/><strong class="ok jh">PTRATIO</strong>: Pupil-teacher ratio by town<br/><strong class="ok jh">B</strong>: 1000(Bk â 0.63)Â², where Bk is the proportion of [people of African American descent] by town<br/><strong class="ok jh">LSTAT</strong>: Percentage of lower status of the population<br/><strong class="ok jh">MEDV</strong>: Median value of owner-occupied homes in $1000s</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="75e2">The last one is our target, and it is not included in the dataframe. Indeed, it is accessible by <code class="fp oh oi oj ok b">boston_dataset.target</code>.</p><h2 class="nr ls jg bm lt ns nt nu lx nv nw nx mb le ny nz md li oa ob mf lm oc od mh oe ga" id="1390">Exploratory data analysis</h2><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="e2c3">This is the part where you discover and familiarise yourself with your data.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="68a4">First of all, itâs a good practice to see if there are any missing values in the data. We count the number of missing values for each feature using <code class="fp oh oi oj ok b">isnull()</code>. In this case, you might not be surprised to discover there is no missing value.<br/>Now, we will use some visualisation to characterise the distribution of our data and to understand how target and feature variables are related.<br/>What we discover is that the distribution is more or less normal, with few outliers.</p><figure class="mp mq mr ms gx mt"><div class="m fs l do"><div class="of og l"></div></div></figure><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm ot"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*7lTqgUgksSG9QYW6V78Rrw.png 640w, https://miro.medium.com/max/720/1*7lTqgUgksSG9QYW6V78Rrw.png 720w, https://miro.medium.com/max/750/1*7lTqgUgksSG9QYW6V78Rrw.png 750w, https://miro.medium.com/max/786/1*7lTqgUgksSG9QYW6V78Rrw.png 786w, https://miro.medium.com/max/828/1*7lTqgUgksSG9QYW6V78Rrw.png 828w, https://miro.medium.com/max/1100/1*7lTqgUgksSG9QYW6V78Rrw.png 1100w, https://miro.medium.com/max/1400/1*7lTqgUgksSG9QYW6V78Rrw.png 1400w"/><img alt="" class="ce my mz c" height="482" loading="lazy" role="presentation" width="700"/></picture></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="d6b9">To better study feature variables one option is the correlation matrix or correlation plots. Since we have quite a few of them, we prefer the correlation matrix, easier to visualise.</p><figure class="mp mq mr ms gx mt"><div class="m fs l do"><div class="of og l"></div></div></figure><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm ou"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*Fzee-qr9kxJBm8nUoiYhNg.png 640w, https://miro.medium.com/max/720/1*Fzee-qr9kxJBm8nUoiYhNg.png 720w, https://miro.medium.com/max/750/1*Fzee-qr9kxJBm8nUoiYhNg.png 750w, https://miro.medium.com/max/786/1*Fzee-qr9kxJBm8nUoiYhNg.png 786w, https://miro.medium.com/max/828/1*Fzee-qr9kxJBm8nUoiYhNg.png 828w, https://miro.medium.com/max/1100/1*Fzee-qr9kxJBm8nUoiYhNg.png 1100w, https://miro.medium.com/max/1400/1*Fzee-qr9kxJBm8nUoiYhNg.png 1400w"/><img alt="" class="ce my mz c" height="560" loading="lazy" role="presentation" width="700"/></picture></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="09ca">What we can notice:</p><ul class=""><li class="ov ow jg kx b ky kz lb lc le ox li oy lm oz lq pa pb pc pd ga" id="64aa">Some of the features have a strong positive correlation, both between them and with the target variable. If we want to go for a linear model, then we reasonably select such features. By looking at the correlation matrix we can see that <code class="fp oh oi oj ok b">RM</code> has a strong positive correlation with the target (0.7) whereas <code class="fp oh oi oj ok b">LSTAT</code> has a high negative correlation with it (-0.74).</li><li class="ov ow jg kx b ky pe lb pf le pg li ph lm pi lq pa pb pc pd ga" id="27d7">For a linear regression model, it might be important is to check for multi-co-linearity. In our case, for example, <code class="fp oh oi oj ok b">RAD</code> and <code class="fp oh oi oj ok b">TAX</code> are really related (intuitively they can be exchanged without losing too much information).</li><li class="ov ow jg kx b ky pe lb pf le pg li ph lm pi lq pa pb pc pd ga" id="4a27">To capture higher correlation orders, one may study the correlation matrix of features squared, or at the third power, etc.</li><li class="ov ow jg kx b ky pe lb pf le pg li ph lm pi lq pa pb pc pd ga" id="bf3e">One can reduce features with some other more systematic methods (like t-SNE, PCA, etc.) and study the correlation of the reduced features with the target variable.</li></ul><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="e257">Based on the above observations we could keep<code class="fp oh oi oj ok b">RM</code> and <code class="fp oh oi oj ok b">LSTAT</code> as our features. However, since this is not the interest of this post, we will ignore this and use all the features.</p><h2 class="nr ls jg bm lt ns nt nu lx nv nw nx mb le ny nz md li oa ob mf lm oc od mh oe ga" id="3a1c">Preparing data to feed the model</h2><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="5ab1">We can collect data into train test split using the popular method of sklearn.</p><figure class="mp mq mr ms gx mt"><div class="m fs l do"><div class="of og l"></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="9d30">There is one last step that is strongly advised to take: clean your data pipeline now. To do so, we will write a simple set of functions. The key-word is â<em class="pj">modular</em>â since you want to re-use this code in other projects and also you may want to maintain this model and maybe add/remove features.</p><figure class="mp mq mr ms gx mt"><div class="m fs l do"><div class="of og l"></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="2447">Note how we used a dictionary to input arguments for the <code class="fp oh oi oj ok b">import_data</code> function. This because we have in mind to feed such function with <code class="fp oh oi oj ok b">json</code> or <code class="fp oh oi oj ok b">yml</code> files through HTTP protocol.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="5648">Since I have already in mind the model I wanna use, I make this further consideration of data normalisation. Some problems may arise in feeding a neural network with data spreading over different intervals (both in size and central point). In principle, a well-trained model should adapt to such differences and encode them properly, however, this requires a lot of data and at the end of the story makes the model more difficult to train, less robust and eventually not precise.<br/>A widespread best practice to deal with such data is to do feature-wise normalization: for each feature in the input data (a column in the input data matrix), we will subtract the mean of the feature and divide by the standard deviation, so that the feature will be centred around 0 and will have a unit standard deviation.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="37a7">Hence we modify the function above as follows,</p><figure class="mp mq mr ms gx mt"><div class="m fs l do"><div class="of og l"></div></div></figure><h1 class="lr ls jg bm lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi ga" id="edb6">1. Model building</h1><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="8b12">At this stage, we design our model and train it in order to evaluate its performances. Normally, this part is done in a notebook without worrying too much about name conventions, functions, OOP, comments, etc. <br/>However, my advice (also here) is to be as much clean as possible, since this can save you from hours of â<em class="pj">converting code into something readable</em>â later.</p><h2 class="nr ls jg bm lt ns nt nu lx nv nw nx mb le ny nz md li oa ob mf lm oc od mh oe ga" id="202e">Algorithm design</h2><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="aeec">Previously performed data analysis should drive this part. For example, a decision tree-based algorithm or an XGBoost would allow you to obtain great results.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="7ff4">Normally this part is made of a trial-error approach. Often you do not want to train your candidates model on the whole dataset (when you have a lot of data), so one solution might be to random sample your training data and train a bunch of models to compare their performances and choose the best one according to your chosen metric.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="7128">An aside, choosing the right metric for the problem is crucial. Of course, this is problem-dependent, however, here we can state the three properties a good metric has to satisfy:</p><ol class=""><li class="ov ow jg kx b ky kz lb lc le ox li oy lm oz lq pk pb pc pd ga" id="6d44">It has to be <strong class="kx jh">single-numbered</strong>. You want to make easy comparisons.</li><li class="ov ow jg kx b ky pe lb pf le pg li ph lm pi lq pk pb pc pd ga" id="7d4c">It has to be <strong class="kx jh">satisficing</strong> with respect to some numerical performance property. <em class="pj">i.e.</em> It has to measure algorithm numerical performances.</li><li class="ov ow jg kx b ky pe lb pf le pg li ph lm pi lq pk pb pc pd ga" id="f9c5">It has to be <strong class="kx jh">optimising</strong>. <em class="pj">i.e.</em> It has to measure algorithm results.</li></ol><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="0bc0">The typical example is: we pick the model with the highest <em class="pj">F1</em>-score and inference time under 10 milliseconds.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="e0c5">Of course, this is an initial analysis. Usually, you may go through the complete training of a couple of different models before choosing the âright oneâ.<br/>Here, we pretend we have done everything properly and we refer to this great post for details.</p><div class="pl pm gt gv pn po"><a href="https://medium.com/structuring-your-machine-learning-projects/satisficing-and-optimizing-metric-24372e0a73c" rel="noopener follow" target="_blank"><div class="pp o fr"><div class="pq o da dx en pr"><h2 class="bm jh dm bo fs ps fu fv pt fx fz jf ga">Satisficing and optimizing metric</h2><div class="pu l"><h3 class="bm b dm bo fs ps fu fv pt fx fz cn">There are different metrics for assessing a classifierâs performance, they are called evaluation matrices. They can beâ¦</h3></div><div class="pv l"><p class="bm b hi bo fs ps fu fv pt fx fz cn">medium.com</p></div></div><div class="pw l"><div class="px l py pz qa pw qb my po"></div></div></div></a></div><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="e2ba">Letâs say from our analysis we have chosen a Neural Network model. Again, my advice is to write your notebook cells always having in mind that you are going to convert this code in production, so be clean!</p><figure class="mp mq mr ms gx mt"><div class="m fs l do"><div class="of og l"></div></div><figcaption class="na bl gn gl gm nb nc bm b bn bo cn">You can start to recognise a pattern. The config dictionary is going to be a json (or yml, or some other similar format) file.</figcaption></figure><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm qc"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*Vm78K5A1Osw1d_P8UGduJg.png 640w, https://miro.medium.com/max/720/1*Vm78K5A1Osw1d_P8UGduJg.png 720w, https://miro.medium.com/max/750/1*Vm78K5A1Osw1d_P8UGduJg.png 750w, https://miro.medium.com/max/786/1*Vm78K5A1Osw1d_P8UGduJg.png 786w, https://miro.medium.com/max/828/1*Vm78K5A1Osw1d_P8UGduJg.png 828w, https://miro.medium.com/max/1100/1*Vm78K5A1Osw1d_P8UGduJg.png 1100w, https://miro.medium.com/max/1400/1*Vm78K5A1Osw1d_P8UGduJg.png 1400w"/><img alt="" class="ce my mz c" height="305" loading="lazy" role="presentation" width="700"/></picture></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="3b29">Once the model is defined and compiled (if you are a PyTorch person, no need for compilation), we are ready to train it on our data.</p><h2 class="nr ls jg bm lt ns nt nu lx nv nw nx mb le ny nz md li oa ob mf lm oc od mh oe ga" id="5bb5">First Training</h2><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="f7a2">Letâs fit the model on our training data and measure the performance on test. To be rigorous, we should also have a validation set, but we will have time to worry about this later on. In this phase, we just want to end up with a working model and a measure of its performances. This is the overcited <em class="pj">quick-and-dirty </em>approach, that has nothing to do with how messy is your code.</p><figure class="mp mq mr ms gx mt"><div class="m fs l do"><div class="of og l"></div></div></figure><h2 class="nr ls jg bm lt ns nt nu lx nv nw nx mb le ny nz md li oa ob mf lm oc od mh oe ga" id="38a0">Model evaluation</h2><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="186f">It is always useful (even more in the regression case) to look at learning curves.</p><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm qd"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*3lE4mBEFLBNT2qPQT2Z2pg.png 640w, https://miro.medium.com/max/720/1*3lE4mBEFLBNT2qPQT2Z2pg.png 720w, https://miro.medium.com/max/750/1*3lE4mBEFLBNT2qPQT2Z2pg.png 750w, https://miro.medium.com/max/786/1*3lE4mBEFLBNT2qPQT2Z2pg.png 786w, https://miro.medium.com/max/828/1*3lE4mBEFLBNT2qPQT2Z2pg.png 828w, https://miro.medium.com/max/1100/1*3lE4mBEFLBNT2qPQT2Z2pg.png 1100w, https://miro.medium.com/max/1400/1*3lE4mBEFLBNT2qPQT2Z2pg.png 1400w"/><img alt="" class="ce my mz c" height="459" loading="lazy" role="presentation" width="700"/></picture></div></div></figure><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm qe"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*aJ305K7UIj1zHGqRt5rVYA.png 640w, https://miro.medium.com/max/720/1*aJ305K7UIj1zHGqRt5rVYA.png 720w, https://miro.medium.com/max/750/1*aJ305K7UIj1zHGqRt5rVYA.png 750w, https://miro.medium.com/max/786/1*aJ305K7UIj1zHGqRt5rVYA.png 786w, https://miro.medium.com/max/828/1*aJ305K7UIj1zHGqRt5rVYA.png 828w, https://miro.medium.com/max/1100/1*aJ305K7UIj1zHGqRt5rVYA.png 1100w, https://miro.medium.com/max/1400/1*aJ305K7UIj1zHGqRt5rVYA.png 1400w"/><img alt="" class="ce my mz c" height="455" loading="lazy" role="presentation" width="700"/></picture></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="2423">We can see how our model is still minimising the loss function. This would suggest increasing the number of epochs.<br/>We have also alternatives, <em class="pj">i.e. </em>increasing the modelisation power of our network, that is modifying its architecture, more hidden units and more hidden layers.<br/>We will try both in the next section.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="07a1">To conclude, an attentive reader may have noticed how the test loss seems to be lower than the training one. This is an effect of the fact that Keras computes the two losses in a slightly different way. I refer to this post for details.</p><div class="pl pm gt gv pn po"><a href="https://www.pyimagesearch.com/2019/10/14/why-is-my-validation-loss-lower-than-my-training-loss/#:~:text=The%20second%20reason%20you%20may,is%20measured%20after%20each%20epoch" rel="noopener ugc nofollow" target="_blank"><div class="pp o fr"><div class="pq o da dx en pr"><h2 class="bm jh dm bo fs ps fu fv pt fx fz jf ga">Why is my validation loss lower than my training loss? - PyImageSearch</h2><div class="pu l"><h3 class="bm b dm bo fs ps fu fv pt fx fz cn">Ever wonder why your validation loss is lower than your training loss? In this tutorial, you will learn the threeâ¦</h3></div><div class="pv l"><p class="bm b hi bo fs ps fu fv pt fx fz cn">www.pyimagesearch.com</p></div></div><div class="pw l"><div class="qf l py pz qa pw qb my po"></div></div></div></a></div><h2 class="nr ls jg bm lt ns nt nu lx nv nw nx mb le ny nz md li oa ob mf lm oc od mh oe ga" id="287b">Hyperparameter choice and optimisation</h2><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="0f62">In the previous section, we ended up with two possible options to improve our model.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="457a">We can try both ways and see which solution gives us the best results on the test-set. We are actually using our test set as a validation one.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="6936">The previous model configuration gave us the plot above. Letâs leave everything unchanged and just increase the number of epochs to 100.<br/>The only thing to do is modify the <code class="fp oh oi oj ok b">config</code> variable as follows.</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="b187">config = {<br/>           'data': boston_dataset,<br/>           'train_test_ratio': 0.2,<br/>           'model_config': {<br/>               'model_name': 'house_pricing_model',<br/>               'layers': {<br/>                        'first_layer': 12, <br/>                        'second_layer': 5, <br/>                        'output_layer': 1<br/>                       },<br/>                'activations': ['relu', 'relu', None],<br/>                'loss_function': 'mse',<br/>                'optimiser': 'adam',<br/>                'metrics': ['mae']<br/>                },<br/>            'training_config': {<br/>                'batch_size': 10,<br/>                'epochs': 100<br/>            }<br/>           }</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="1da5">Everything else stays the same, we can reinitialise our model and run the train function again. We get,</p><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm qg"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*6bFS78Nncnu-JFdSC04k5Q.png 640w, https://miro.medium.com/max/720/1*6bFS78Nncnu-JFdSC04k5Q.png 720w, https://miro.medium.com/max/750/1*6bFS78Nncnu-JFdSC04k5Q.png 750w, https://miro.medium.com/max/786/1*6bFS78Nncnu-JFdSC04k5Q.png 786w, https://miro.medium.com/max/828/1*6bFS78Nncnu-JFdSC04k5Q.png 828w, https://miro.medium.com/max/1100/1*6bFS78Nncnu-JFdSC04k5Q.png 1100w, https://miro.medium.com/max/1400/1*6bFS78Nncnu-JFdSC04k5Q.png 1400w"/><img alt="" class="ce my mz c" height="88" loading="lazy" role="presentation" width="700"/></picture></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="9f1d">while learning curves look like</p><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm qh"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*cRtq_AU5s85gRyDAY9vggw.png 640w, https://miro.medium.com/max/720/1*cRtq_AU5s85gRyDAY9vggw.png 720w, https://miro.medium.com/max/750/1*cRtq_AU5s85gRyDAY9vggw.png 750w, https://miro.medium.com/max/786/1*cRtq_AU5s85gRyDAY9vggw.png 786w, https://miro.medium.com/max/828/1*cRtq_AU5s85gRyDAY9vggw.png 828w, https://miro.medium.com/max/1100/1*cRtq_AU5s85gRyDAY9vggw.png 1100w, https://miro.medium.com/max/1400/1*cRtq_AU5s85gRyDAY9vggw.png 1400w"/><img alt="" class="ce my mz c" height="471" loading="lazy" role="presentation" width="700"/></picture></div></div></figure><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm qi"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*-s7GkPIduy7uYl9CEVTLUQ.png 640w, https://miro.medium.com/max/720/1*-s7GkPIduy7uYl9CEVTLUQ.png 720w, https://miro.medium.com/max/750/1*-s7GkPIduy7uYl9CEVTLUQ.png 750w, https://miro.medium.com/max/786/1*-s7GkPIduy7uYl9CEVTLUQ.png 786w, https://miro.medium.com/max/828/1*-s7GkPIduy7uYl9CEVTLUQ.png 828w, https://miro.medium.com/max/1100/1*-s7GkPIduy7uYl9CEVTLUQ.png 1100w, https://miro.medium.com/max/1400/1*-s7GkPIduy7uYl9CEVTLUQ.png 1400w"/><img alt="" class="ce my mz c" height="459" loading="lazy" role="presentation" width="700"/></picture></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="dbdb">Great result! We cannot see overfitting issues and loss stabilises between around 85/90 epochs.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="9d63">In order to give some meaning to the value of the error, we have to look at the target variable. <code class="fp oh oi oj ok b">df.target.describe()</code> (and the histogram we plotted earlier) gives us the information we want.</p><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="gl gm qj"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 498px" srcset="https://miro.medium.com/max/640/1*pkKWuhScw5kdLtKOsxmcDw.png 640w, https://miro.medium.com/max/720/1*pkKWuhScw5kdLtKOsxmcDw.png 720w, https://miro.medium.com/max/750/1*pkKWuhScw5kdLtKOsxmcDw.png 750w, https://miro.medium.com/max/786/1*pkKWuhScw5kdLtKOsxmcDw.png 786w, https://miro.medium.com/max/828/1*pkKWuhScw5kdLtKOsxmcDw.png 828w, https://miro.medium.com/max/1100/1*pkKWuhScw5kdLtKOsxmcDw.png 1100w, https://miro.medium.com/max/996/1*pkKWuhScw5kdLtKOsxmcDw.png 996w"/><img alt="" class="ce my mz c" height="328" loading="lazy" role="presentation" width="498"/></picture></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="6e7f">We can see how a mean absolute error of ~2.3 corresponds to an error of more or less the 10% on the average of our data.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="6c4d"><em class="pj">NOTE</em>: To make our error estimation more robust, we should operate k-fold cross-validation and take as mean absolute error value the average over the folds. We will neglect this here for the sake of readability.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="dc1b">Letâs try the other option and modify the number of hidden units and hidden layers.</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="ae8f">config = {<br/>           'data': boston_dataset,<br/>           'train_test_ratio': 0.2,<br/>           'model_config': {<br/>               'model_name': 'house_pricing_model',<br/>               'layers': {<br/>                        'first_layer': 64, <br/>                        'second_layer': 64,<br/>                        'third_layer': 32,<br/>                        'output_layer': 1<br/>                       },<br/>                'activations': ['relu', 'relu', 'relu', None], # Regression problem: no activation in the last layer.<br/>                'loss_function': 'mse',<br/>                'optimiser': 'adam',<br/>                'metrics': ['mae']<br/>                },<br/>            'training_config': {<br/>                'batch_size': 10,<br/>                'epochs': 100<br/>            }<br/>           }</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="083f">We added a layer and increased the number of hidden units in each layer. Letâs train with such a configuration.</p><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm qk"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*SLEQ061L7Nx8VzMX4Z9tJg.png 640w, https://miro.medium.com/max/720/1*SLEQ061L7Nx8VzMX4Z9tJg.png 720w, https://miro.medium.com/max/750/1*SLEQ061L7Nx8VzMX4Z9tJg.png 750w, https://miro.medium.com/max/786/1*SLEQ061L7Nx8VzMX4Z9tJg.png 786w, https://miro.medium.com/max/828/1*SLEQ061L7Nx8VzMX4Z9tJg.png 828w, https://miro.medium.com/max/1100/1*SLEQ061L7Nx8VzMX4Z9tJg.png 1100w, https://miro.medium.com/max/1400/1*SLEQ061L7Nx8VzMX4Z9tJg.png 1400w"/><img alt="" class="ce my mz c" height="96" loading="lazy" role="presentation" width="700"/></picture></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="9b76">Numbers are slightly improved! Letâs look at learning curves.</p><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm qd"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*eJNTbArG3JjTbKnNEELGqw.png 640w, https://miro.medium.com/max/720/1*eJNTbArG3JjTbKnNEELGqw.png 720w, https://miro.medium.com/max/750/1*eJNTbArG3JjTbKnNEELGqw.png 750w, https://miro.medium.com/max/786/1*eJNTbArG3JjTbKnNEELGqw.png 786w, https://miro.medium.com/max/828/1*eJNTbArG3JjTbKnNEELGqw.png 828w, https://miro.medium.com/max/1100/1*eJNTbArG3JjTbKnNEELGqw.png 1100w, https://miro.medium.com/max/1400/1*eJNTbArG3JjTbKnNEELGqw.png 1400w"/><img alt="" class="ce my mz c" height="458" loading="lazy" role="presentation" width="700"/></picture></div></div></figure><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm ql"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*FVLns2n5DF0jlFl5xHRIgg.png 640w, https://miro.medium.com/max/720/1*FVLns2n5DF0jlFl5xHRIgg.png 720w, https://miro.medium.com/max/750/1*FVLns2n5DF0jlFl5xHRIgg.png 750w, https://miro.medium.com/max/786/1*FVLns2n5DF0jlFl5xHRIgg.png 786w, https://miro.medium.com/max/828/1*FVLns2n5DF0jlFl5xHRIgg.png 828w, https://miro.medium.com/max/1100/1*FVLns2n5DF0jlFl5xHRIgg.png 1100w, https://miro.medium.com/max/1400/1*FVLns2n5DF0jlFl5xHRIgg.png 1400w"/><img alt="" class="ce my mz c" height="464" loading="lazy" role="presentation" width="700"/></picture></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="c960">They are good, but we start to see the nemesis of any data scientist: overfitting. Around epoch 15/20 training loss became systematically lower than test loss, and such divergence grows with epochs.<br/>We can lower the number of epochs, or insert a Dropout layer to reduce the overfit. And so on, until we are happy with the result.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="dcf8">For our purposes, we will stop here and choose the following configuration.</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="e1d2">config = {<br/>           'data': boston_dataset,<br/>           'train_test_ratio': 0.2,<br/>           'model_config': {<br/>               'model_name': 'house_pricing_model',<br/>               'layers': {<br/>                        'first_layer': 64, <br/>                        'second_layer': 64,<br/>                        'third_layer': 32,<br/>                        'output_layer': 1<br/>                       },<br/>                'activations': ['relu', 'relu', 'relu', None], <br/>                'loss_function': 'mse',<br/>                'optimiser': 'adam',<br/>                'metrics': ['mae']<br/>                },<br/>            'training_config': {<br/>                'batch_size': 10,<br/>                'epochs': 17<br/>            }<br/>           }</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="f234"><strong class="kx jh">Optuna</strong></p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="bf2d">Another more efficient option is to look for the best hyperparameter configuration with a library. <a class="au nd" href="https://optuna.org/" rel="noopener ugc nofollow" target="_blank"><em class="pj">Optuna</em></a> is a library that does exactly this, recently they introduced also an experimental feature looking for the best model architecture. My advice is to try it out.</p><div class="pl pm gt gv pn po"><a href="https://medium.com/optuna/using-optuna-to-optimize-tensorflow-hyperparameters-57b6d4d316a2" rel="noopener follow" target="_blank"><div class="pp o fr"><div class="pq o da dx en pr"><h2 class="bm jh dm bo fs ps fu fv pt fx fz jf ga">Using Optuna to Optimize TensorFlow Hyperparameters</h2><div class="pu l"><h3 class="bm b dm bo fs ps fu fv pt fx fz cn">Automate the tuning of hyperparameters in TensorFlow using Bayesian Optimisation in Optuna</h3></div><div class="pv l"><p class="bm b hi bo fs ps fu fv pt fx fz cn">medium.com</p></div></div><div class="pw l"><div class="qm l py pz qa pw qb my po"></div></div></div></a></div><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="b6ff">Hyperparameter optimisation is a really fascinating topic and it would require a series of posts on its own, but for this article, letâs follow our guided-example and go on to build the training pipeline.</p><h2 class="nr ls jg bm lt ns nt nu lx nv nw nx mb le ny nz md li oa ob mf lm oc od mh oe ga" id="31f7">Pipeline construction</h2><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="02a5">Since I want to focus on the serving part, here I will keep the training pipeline simple, however, you can make this as involved as you want. For instance, one can build another app to build and train your model.<br/>Strictly speaking, one could also train the model in a notebook than save the model file and export it. This can be done, however, I would advise against it, because a notebook has no versioning system, you cannot check whether you introduced some non-compatibility issues, etc.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="a809">Here we will adopt a half-way solution: we will create a script, taking a config file as input (the only one you should modify in the successive versions of your model) and returning a saved model file.<br/>Since we put some attention in writing the cells of our notebook, the script is quite easy to create.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="0a69">We will make use of an auxiliary library since our script will be executed by a command-line interface and we want to pass the config file path as an argument without touching the script code.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="e3a8">The script is really brief and very schematic.</p><figure class="mp mq mr ms gx mt"><div class="m fs l do"><div class="of og l"></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="72e6">Note that we imported an <code class="fp oh oi oj ok b">utils</code> module, which is a collection of the functions we defined above. Note also that this is not the cleanest way to do things, we could (and normally we should) modularise even more, and even better, create classes collecting methods for our model.</p><figure class="mp mq mr ms gx mt"><div class="m fs l do"><div class="of og l"></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="c4fc">As a bonus, you can transform this training script into a command, <em class="pj">i.e. </em>you will turn</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="9372">python3 -m estimator train --conf config.json</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="d5b7">into</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="e00d">estimator train --conf config.json</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="17b6">To do so, you can read this nice medium post.</p><div class="pl pm gt gv pn po"><a href="https://christopherdoucette.medium.com/turning-python-scripts-into-cli-commands-aecf56dfda18" rel="noopener follow" target="_blank"><div class="pp o fr"><div class="pq o da dx en pr"><h2 class="bm jh dm bo fs ps fu fv pt fx fz jf ga">Turning Python Scripts into CLI Commands</h2><div class="pu l"><h3 class="bm b dm bo fs ps fu fv pt fx fz cn">In this article, we are exploring how you can turn your Python scripts into fully-fledged CLI commands</h3></div><div class="pv l"><p class="bm b hi bo fs ps fu fv pt fx fz cn">christopherdoucette.medium.com</p></div></div><div class="pw l"><div class="qn l py pz qa pw qb my po"></div></div></div></a></div><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="2025">The <code class="fp oh oi oj ok b">config.json</code> file contains all the information to define and train our model.</p><figure class="mp mq mr ms gx mt"><div class="m fs l do"><div class="of og l"></div></div></figure><h2 class="nr ls jg bm lt ns nt nu lx nv nw nx mb le ny nz md li oa ob mf lm oc od mh oe ga" id="5c57">Model training</h2><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="1734">Finally, we are ready to run the proper training of our chosen model. Once the model is fitted, we save it to export and serve it to the next-section-coming API.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="aa2c">This is automatically done by one single command in a command-line shell:</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="f6ac">python3 -m estimator train --conf config.json</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="2e71"><em class="pj">NOTE</em>: To not make this too long post even longer, here I am not considering one of the greatest features in Keras: callbacks. One can set a metric and monitor it during training in order to automatically stop the fit when your model does not improve over epochs, or save automatically the best metric result, no matter in which epoch it has been reached, etc. A great source for reference is the <a class="au nd" href="https://www.tensorflow.org/guide/keras/custom_callback" rel="noopener ugc nofollow" target="_blank">official documentation of Tensorflow</a>.</p></div><div class="o dx nf ng ii nh" role="separator"><span class="ni fl ci nj nk nl"></span><span class="ni fl ci nj nk nl"></span><span class="ni fl ci nj nk"></span></div><div class="iz ja jb jc jd"><h1 class="lr ls jg bm lt lu nm lw lx ly nn ma mb km no kn md kp np kq mf ks nq kt mh mi ga" id="3936">2. Deploy</h1><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="7deb">Now that your model is trained and saved somewhere locally, we are able to start the fascinating chapter of deployment.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="ebbd">By this dark and evil word, we simply mean making our model available and reachable (from users or other applications) in order to provide predictions.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="9184">The scheme is simple: we want to put our model somewhere, make it receive <em class="pj">requests</em> and give back predictions. In our example, we want to feed the model with houses (more appropriately with feature vectors describing houses) and get as <em class="pj">response</em> price predictions for the house fed in.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="af50">Since we do not want to be the only users or our model, we have to choose a protocol that is publicly (or at least to a certain list of users) accessible from outside our local system.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="f7dc">One of the major ideas in modern computer science is <a class="au nd" href="https://www.sumologic.com/glossary/container/" rel="noopener ugc nofollow" target="_blank"><em class="pj">containerisation</em></a><em class="pj">. </em>By this, we mean bundling an application together with all of its related configuration files, libraries and dependencies required for it to run in an efficient and bug-free way across different computing environments. Going on this path, we split our complex applications into packages and then we compose containers together in other to make them without worrying about the system they are going to be executed on.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="3dd4">A great source to learn about containers is the nice medium post below.</p><div class="pl pm gt gv pn po"><a href="https://medium.com/cycleplatform/a-brief-introduction-to-containers-d34e64e61bc1" rel="noopener follow" target="_blank"><div class="pp o fr"><div class="pq o da dx en pr"><h2 class="bm jh dm bo fs ps fu fv pt fx fz jf ga">A Brief Introduction to Containers</h2><div class="pu l"><h3 class="bm b dm bo fs ps fu fv pt fx fz cn">Whether youâre new to development or a seasoned developer, containers have proven to be game-changing in building toâ¦</h3></div><div class="pv l"><p class="bm b hi bo fs ps fu fv pt fx fz cn">medium.com</p></div></div><div class="pw l"><div class="qo l py pz qa pw qb my po"></div></div></div></a></div><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm qp"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*BvgKQ2SXt8h2yvMu13eZQA.png 640w, https://miro.medium.com/max/720/1*BvgKQ2SXt8h2yvMu13eZQA.png 720w, https://miro.medium.com/max/750/1*BvgKQ2SXt8h2yvMu13eZQA.png 750w, https://miro.medium.com/max/786/1*BvgKQ2SXt8h2yvMu13eZQA.png 786w, https://miro.medium.com/max/828/1*BvgKQ2SXt8h2yvMu13eZQA.png 828w, https://miro.medium.com/max/1100/1*BvgKQ2SXt8h2yvMu13eZQA.png 1100w, https://miro.medium.com/max/1400/1*BvgKQ2SXt8h2yvMu13eZQA.png 1400w"/><img alt="" class="ce my mz c" height="419" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="na bl gn gl gm nb nc bm b bn bo cn">An even poorlier drawn image by the author. We added the numbers referring to the steps below.</figcaption></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="7ebd">In this spirit, and following the scheme in the figure above, we have to:</p><ol class=""><li class="ov ow jg kx b ky kz lb lc le ox li oy lm oz lq pk pb pc pd ga" id="3c76">Create an API to serve our model. We will do this by using FastAPI.</li><li class="ov ow jg kx b ky pe lb pf le pg li ph lm pi lq pk pb pc pd ga" id="0d3e">Containerise our API. We will do this by Docker.</li><li class="ov ow jg kx b ky pe lb pf le pg li ph lm pi lq pk pb pc pd ga" id="05e3">Push the docker image on some service. We are going to use AWS ECR.</li><li class="ov ow jg kx b ky pe lb pf le pg li ph lm pi lq pk pb pc pd ga" id="765e">Deploy the docker container containing the app on some service. We will make use of a virtual machine service: AWS EC2.</li></ol><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="e615">Note that these steps are more or less the same as any other software application to be deployed.</p><blockquote class="qq qr qs"><p class="kv kw pj kx b ky kz kh la lb lc kk ld qt lf lg lh qu lj lk ll qv ln lo lp lq iz ga" id="3612">Data scientist are (among other things) developers and must be able to follow the typical <a class="au nd" href="https://en.wikipedia.org/wiki/Software_release_life_cycle" rel="noopener ugc nofollow" target="_blank">software life-cycle</a>.</p></blockquote><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="6b60">Indeed one can follow these very same steps also and deploy the âhello worldâ API (<em class="pj">i.e. </em>the to-do list). This is actually a very nice exercise and can be used to practice such a procedure. To develop the to-do list API one can refer to the following article.</p><div class="pl pm gt gv pn po"><a href="https://surikavii.medium.com/making-a-todo-app-from-a-beginners-perspective-part-1-intro-to-fastapi-5006abbcb7a2" rel="noopener follow" target="_blank"><div class="pp o fr"><div class="pq o da dx en pr"><h2 class="bm jh dm bo fs ps fu fv pt fx fz jf ga">Making a Todo app from a beginners perspective. Part: 1 Intro to FastAPI</h2><div class="pu l"><h3 class="bm b dm bo fs ps fu fv pt fx fz cn">The what why and how</h3></div><div class="pv l"><p class="bm b hi bo fs ps fu fv pt fx fz cn">surikavii.medium.com</p></div></div><div class="pw l"><div class="qw l py pz qa pw qb my po"></div></div></div></a></div><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="2545">Do not get scared, these parts are quite straightforward. Here there is no analysis to take into account, no trial-error approach. The objects we are going to define here are mostly a copy-paste of code handed down for generations of fellow programmers.</p><h2 class="nr ls jg bm lt ns nt nu lx nv nw nx mb le ny nz md li oa ob mf lm oc od mh oe ga" id="889d">API Creation</h2><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="5b5e">We are going to use FastAPI, which is one of the possible web frameworks you can use to convert your Python code into an app communicating by HTTP protocol.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="8805">The advantage of FastAPI is that is fast (almost as a compiled language), easy to learn, widely used (a lot of online support), and it builds handy online documentation for your app.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="1fd9">So letâs build our app.<br/>We need to create the following directory structure:</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="ac14">âââ __init__.py</span><span class="ga nr ls jg ok b dm qx oq l or os" id="1b51">âââ ai</span><span class="ga nr ls jg ok b dm qx oq l or os" id="c67b">|  âââ __init__.py</span><span class="ga nr ls jg ok b dm qx oq l or os" id="9962">|  âââ regressor.py</span><span class="ga nr ls jg ok b dm qx oq l or os" id="9dda">|  âââ services.py</span><span class="ga nr ls jg ok b dm qx oq l or os" id="db21">âââ main.py</span><span class="ga nr ls jg ok b dm qx oq l or os" id="460f">âââ model</span><span class="ga nr ls jg ok b dm qx oq l or os" id="1366">|  âââ model.h5</span><span class="ga nr ls jg ok b dm qx oq l or os" id="a7b1">âââ schemas</span><span class="ga nr ls jg ok b dm qx oq l or os" id="d07b">|  âââ __init__.py</span><span class="ga nr ls jg ok b dm qx oq l or os" id="b67a">ââââââ schemas.py</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="f94e">This is not strictly necessary, you can have everything in the same file (may the gods forgive you), or you can use frameworks structuring your Python project for you, <em class="pj">e.g.</em> <a class="au nd" href="https://github.com/cookiecutter/cookiecutter" rel="noopener ugc nofollow" target="_blank">cookie-cutter</a>. However, I strongly advise following a fixed schema to get used to such structures.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="1d08">We will explore each file individually.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="5fed">Letâs start from the main, which is the file we are going to launch to execute our app.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="f2a8"><strong class="kx jh">main.py</strong></p><figure class="mp mq mr ms gx mt"><div class="m fs l do"><div class="of og l"></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="7864">You can see, the code is quite self-explanatory and even without knowing the exact implementation of the function you can say what this app does at high level. It receives data (of type <code class="fp oh oi oj ok b">InputData</code> ) and returns a dictionary (actually a type <code class="fp oh oi oj ok b">ResponseDataAPI</code>, see function decorator) containing input data and predictions.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="53d8">In FastAPI decorators are used to define the HTTP methods, in our app we only need a get (to check the status of the app) and a post (to send the data and obtain predictions).</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="9eaf">We can run the app locally by the terminal command</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="f16e">uvicorn main:app --reload</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="b0fe">Opening a browser and going to the local address <a class="au nd" href="http://127.0.0.1:8000/docs" rel="noopener ugc nofollow" target="_blank">http://127.0.0.1:8000/docs</a> we will see the automatic interactive API documentation (provided by <a class="au nd" href="https://github.com/swagger-api/swagger-ui" rel="noopener ugc nofollow" target="_blank">Swagger UI</a>). You can access the alternative documentation page at <a class="au nd" href="http://127.0.0.1:8000/redoc" rel="noopener ugc nofollow" target="_blank">http://127.0.0.1:8000/redoc</a>.</p><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm qy"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*rzWBma4fxBRaau4romhNPw.png 640w, https://miro.medium.com/max/720/1*rzWBma4fxBRaau4romhNPw.png 720w, https://miro.medium.com/max/750/1*rzWBma4fxBRaau4romhNPw.png 750w, https://miro.medium.com/max/786/1*rzWBma4fxBRaau4romhNPw.png 786w, https://miro.medium.com/max/828/1*rzWBma4fxBRaau4romhNPw.png 828w, https://miro.medium.com/max/1100/1*rzWBma4fxBRaau4romhNPw.png 1100w, https://miro.medium.com/max/1400/1*rzWBma4fxBRaau4romhNPw.png 1400w"/><img alt="" class="ce my mz c" height="289" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="na bl gn gl gm nb nc bm b bn bo cn">This is what you should see. Image by the author.</figcaption></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="7cfa">There is plenty of functionalities to explore (and a good reference to look at is always the very well written <a class="au nd" href="https://fastapi.tiangolo.com/" rel="noopener ugc nofollow" target="_blank">FastAPI documentation</a>), here I just want to mention two main aspects:<br/><em class="pj">1.</em> The API comes automatically with a web interface. This allows you to show the working scheme of your model even to some non-tech fellow. And this comes for free.<br/><em class="pj">2.</em> You have an URL that can be interrogated with json strings and responds in the same format. This is really useful to go in production, <em class="pj">i.e.</em> you can host this app on a web server and start integrating with other apps, that is the key to production procedures.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="5e06">This second aspect may be explicitly interrogated by terminal</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="fb58">curl -X 'POST' \<br/>  '<a class="au nd" href="http://127.0.0.1:8000/docs" rel="noopener ugc nofollow" target="_blank">http://127.0.0.1:8000/</a>v1/services/predict<!-- -->' \<br/>  -H 'accept: application/json' \<br/>  -H 'Content-Type: application/json' \<br/>  -d '[<br/>  {<br/>    "<!-- -->CRIM": "float", <br/>    "ZN": "float", <br/>    "INDUS": "float", <br/>    "CHAS": "int", <br/>    "NOX": "float", <br/>    "RM": "float", <br/>    "AGE": "float", <br/>    "DIS": "float", <br/>    "RAD": "float", <br/>    "TAX": "float",<br/>    "PTRATIO": "float", <br/>    "B": "float", <br/>    "LSTAT<!-- -->": "string"<br/>  }<br/>]'</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="da4d">Note we have to provide the examples in a json collecting all the features we have trained the model on. We may have changed the name, but because of a lack of imagination, we left them unchanged with respect to the initial dataset.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="082d">Thus, for instance, to get a prediction, we can give the terminal command</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="e4f2">curl -X 'POST' \<br/>  '<a class="au nd" href="http://127.0.0.1:8000/docs" rel="noopener ugc nofollow" target="_blank">http://127.0.0.1:8000/</a>v1/services/predict<!-- -->' \<br/>  -H 'accept: application/json' \<br/>  -H 'Content-Type: application/json' \<br/>  -d '[<br/>  {<br/>    "<!-- -->CRIM": 0.09178, <br/>    "ZN": 0.0, <br/>    "INDUS": 4.05, <br/>    "CHAS": 0, <br/>    "NOX": 0.510, <br/>    "RM": 6.416, <br/>    "AGE": 84.1, <br/>    "DIS": 2.6463, <br/>    "RAD": 5.0, <br/>    "TAX": 296.0,<br/>    "PTRATIO": 16.6, <br/>    "B": 395.50, <br/>    "LSTAT<!-- -->": 9.04<br/>  }<br/>]'</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="b2fd">and the API response will be printed on the screen</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="770c">{<br/> "inputData": <br/>  [<!-- -->{<br/>    "<!-- -->CRIM": 0.09178, <br/>    "ZN": 0.0, <br/>    "INDUS": 4.05, <br/>    "CHAS": 0, <br/>    "NOX": 0.510, <br/>    "RM": 6.416, <br/>    "AGE": 84.1, <br/>    "DIS": 2.6463, <br/>    "RAD": 5.0, <br/>    "TAX": 296.0,<br/>    "PTRATIO": 16.6, <br/>    "B": 395.50, <br/>    "LSTAT<!-- -->": 9.04<br/>  }],<br/> "predictions": [{"Prediction price 0": 26.900973}]<br/>}</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="81dc"><strong class="kx jh">ai/regressor.py</strong></p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="74d3">This is the file containing the class definition of our model. We define the <code class="fp oh oi oj ok b">PriceEstimator</code> class and give a minimal amount of methods. Usually, you do not want someone can train your model from the API, hence there is no <code class="fp oh oi oj ok b">train</code> method for this object. There is the <code class="fp oh oi oj ok b">predict</code> one thou since you want to expose your model for predictions.</p><figure class="mp mq mr ms gx mt"><div class="m fs l do"><div class="of og l"></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="c59d">You can recognise the very same function we used in the data pipeline. The driving force of any programmer should be laziness. <br/>In this context, a cleaner approach would be to simply import the same function from the module we have defined earlier, although this, usually, you want to keep the training part of your code and the prediction part well separated.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="cd46"><strong class="kx jh">ai/services.py</strong></p><figure class="mp mq mr ms gx mt"><div class="m fs l do"><div class="of og l"></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="0712">This file contains the code to return the prediction and the load of the model from a pretrained saved file. Note how we read the <code class="fp oh oi oj ok b">MODEL_FOLDER</code> variable from the environment. This means (to run the app locally) that we have to add the model path to the environment. How you do this depends on the OS, a quick google search will give you the answer. On linux/mac this can be done in a terminal by</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="e9fa">export MODEL_FOLDER='path/to/your/model'</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="f62c"><strong class="kx jh">schemas/schemas.py</strong></p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="1f06">This file is the one defining the custom types (in Python any object is a type) of input and output of our app.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="9b4b">Everyone knows Python is a dynamically typed programming language, meaning the type of variables is not declared, bu inferred by their value, and can also change during the execution of a program.<br/>This behaviour is really handy since you do not bother in defining variable types, in keeping attention to never assign the same variable name to values of different types, etc. However, this is also one of the main reasons why Python is so slow in comparison with some other statically typed language, like C/C++, Go, etc.<br/>For a detailed discussion, one can read <a class="au nd" href="http://gallium.inria.fr/~remy/mpri/cours1.pdf" rel="noopener ugc nofollow" target="_blank">this extremely interesting reference</a> or the <a class="au nd" href="https://en.wikipedia.org/wiki/Type_system" rel="noopener ugc nofollow" target="_blank">relative Wikipedia page</a>.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="d8cd">We already pointed out the reason we want to use a web framework like FastAPI is that it is almost as fast as a compiled language, this is reached by slightly modifying such behaviour about type declaration by allowing it.<br/>Hence, we will define and set a fixed type for input and output data.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="0996">This is done by the <code class="fp oh oi oj ok b"><a class="au nd" href="https://docs.python.org/3/library/typing.html" rel="noopener ugc nofollow" target="_blank">typing</a></code><a class="au nd" href="https://docs.python.org/3/library/typing.html" rel="noopener ugc nofollow" target="_blank"> library</a>, which is not a real type declaration, but more a hint. In such a way, we allow the Python interpreter to allocate the right quantity of memory for the âdeclaredâ type.</p><figure class="mp mq mr ms gx mt"><div class="m fs l do"><div class="of og l"></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="9b5e">We defined an example that can be shown on the interactive doc page of FastAPI.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="6ad8">Note how we defined here the types we declare in the main.py functions.</p><h2 class="nr ls jg bm lt ns nt nu lx nv nw nx mb le ny nz md li oa ob mf lm oc od mh oe ga" id="9d7a">Dockerise the FastAPI</h2><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="0505">We are now ready to dockerise our app. <br/>We already discussed why containers are crucial in the modern software industry. Here I just wanna synthesise a problem that docker solves.</p><blockquote class="qq qr qs"><p class="kv kw pj kx b ky kz kh la lb lc kk ld qt lf lg lh qu lj lk ll qv ln lo lp lq iz ga" id="3d95"><em class="jg">A</em>: Look how cool my model is. Iâll send you the script, so you can execute on your machine.<br/><em class="jg">B</em>: Received, however it gives me an error while importing xxx library, I solved by Stack-Overflow, and now my numbers are different than yours.<br/><em class="jg">A</em>: Come and look at my screen, here it works as expected.</p></blockquote><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="8990">If A sent B a docker image, this would have never happened.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="fff8">Letâs see how to dockerise our API. To dockerize the application, first, you need a Dockerfile</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="7e07">Dockerfiles describe how to assemble a private filesystem for a container, and can also contain some metadata describing how to run a container based on the image. (Recall the difference between image and containers, <a class="au nd" href="https://phoenixnap.com/kb/docker-image-vs-container" rel="noopener ugc nofollow" target="_blank">here</a>).</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="1a61">We will also use a file called <code class="fp oh oi oj ok b">requirements.txt</code>, a list of all the libraries we used in the project and their version. We want our app to run without compatibility issues on any machine.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="e37d">As said, the following part can be presented really schematically and here I closely follow the excellent post below, just adapting commands to the present case.</p><div class="pl pm gt gv pn po"><a href="https://medium.com/@meetakoti.kirankumar/deploying-fastapi-web-application-in-aws-a1995675087d" rel="noopener follow" target="_blank"><div class="pp o fr"><div class="pq o da dx en pr"><h2 class="bm jh dm bo fs ps fu fv pt fx fz jf ga">Deploying FastAPI Web Application in AWS</h2><div class="pu l"><h3 class="bm b dm bo fs ps fu fv pt fx fz cn">A step by step guide to deploy FastAPI application in AWS.</h3></div><div class="pv l"><p class="bm b hi bo fs ps fu fv pt fx fz cn">medium.com</p></div></div><div class="pw l"><div class="qz l py pz qa pw qb my po"></div></div></div></a></div><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="03b2"><em class="pj">i) Create a docker file</em></p><figure class="mp mq mr ms gx mt"><div class="m fs l do"><div class="of og l"></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="63b3">Here we make our app run at the address <a class="au nd" href="http://0.0.0.0:5000" rel="noopener ugc nofollow" target="_blank"><em class="pj">http://0.0.0.0:5000</em></a>. <br/>Note how we defined the model location as an environment variable: this is because our app reads such value from the environment.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="f4e5"><em class="pj">ii) Build Docker Image:</em></p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="4fdf">This is done by a line command</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="9179">docker build -t price_estimator_api:latest .</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="10a8"><em class="pj">iii) Run the docker image</em></p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="8029">Now the easy part: letâs run the docker.</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="1af6">docker run -p 5000:5000 price_estimator_api:latest</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="64fa">You can verify the app running by opening a browser at the page <a class="au nd" href="http://localhost:5000/docs" rel="noopener ugc nofollow" target="_blank"><em class="pj">http://localhost:5000/docs</em></a><em class="pj">.</em></p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="d5ec">To learn more about Docker, you can look at the official tutorials.</p><div class="pl pm gt gv pn po"><a href="https://docs.docker.com/get-started/overview/" rel="noopener ugc nofollow" target="_blank"><div class="pp o fr"><div class="pq o da dx en pr"><h2 class="bm jh dm bo fs ps fu fv pt fx fz jf ga">Docker overview</h2><div class="pu l"><h3 class="bm b dm bo fs ps fu fv pt fx fz cn">Docker is an open platform for developing, shipping, and running applications. Docker enables you to separate yourâ¦</h3></div><div class="pv l"><p class="bm b hi bo fs ps fu fv pt fx fz cn">docs.docker.com</p></div></div><div class="pw l"><div class="ra l py pz qa pw qb my po"></div></div></div></a></div><h2 class="nr ls jg bm lt ns nt nu lx nv nw nx mb le ny nz md li oa ob mf lm oc od mh oe ga" id="3d7c">Push on Amazon Elastic Container Registry</h2><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="17f6">Now that you verified that your app container is running locally, we are ready to move it to some accessible âplaceâ. This can be any server with public (or at least non-local) access. Here we want to use the AWS EC2 service.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="e88d">We do not want to bother thinking about machine configuration, scalability, etc. So we will put the docker image on a docker registry, the Amazon Elastic Container Registry (ECR). This is a fully-managed <a class="au nd" href="https://aws.amazon.com/docker/" rel="noopener ugc nofollow" target="_blank">Docker</a> container registry that makes it easy for developers to store, manage, and deploy Docker container images.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="08d8">First, in order to push docker images to ECS, you need to install and configure AWS CLI. Instructions are available on the AWS website.</p><div class="pl pm gt gv pn po"><a href="https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-mac.html" rel="noopener ugc nofollow" target="_blank"><div class="pp o fr"><div class="pq o da dx en pr"><h2 class="bm jh dm bo fs ps fu fv pt fx fz jf ga">Installing, updating, and uninstalling the AWS CLI version 2 on macOS</h2><div class="pu l"><h3 class="bm b dm bo fs ps fu fv pt fx fz cn">AWS CLI versions 1 and 2 use the same aws command name. If you have both versions installed, your computer uses theâ¦</h3></div><div class="pv l"><p class="bm b hi bo fs ps fu fv pt fx fz cn">docs.aws.amazon.com</p></div></div></div></a></div><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="eded">One way to configure the AWS CLI is getting access key ID and Secret Access Key from <strong class="kx jh">Identity and Access Management (IAM) in the AWS console.</strong></p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="5c38">You simply create new access keys and store them for future purposes.</p><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm rb"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/0*ZIM1md6RzCpiHPSo.png 640w, https://miro.medium.com/max/720/0*ZIM1md6RzCpiHPSo.png 720w, https://miro.medium.com/max/750/0*ZIM1md6RzCpiHPSo.png 750w, https://miro.medium.com/max/786/0*ZIM1md6RzCpiHPSo.png 786w, https://miro.medium.com/max/828/0*ZIM1md6RzCpiHPSo.png 828w, https://miro.medium.com/max/1100/0*ZIM1md6RzCpiHPSo.png 1100w, https://miro.medium.com/max/1400/0*ZIM1md6RzCpiHPSo.png 1400w"/><img alt="" class="ce my mz c" height="380" loading="lazy" role="presentation" width="700"/></picture></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="673f">In a terminal, you can configure access.</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="912f">aws configure</span><span class="ga nr ls jg ok b dm qx oq l or os" id="0885">AWS Access Key ID [None]: <strong class="ok jh"><em class="pj">AKIAIOSFODNN7EXAMPLE</em></strong><br/>AWS Secret Access Key [None]:<strong class="ok jh"><em class="pj">wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY</em></strong><br/>Default region name [None]: <strong class="ok jh"><em class="pj">eu-west-3</em></strong><br/>Default output format [None]:<strong class="ok jh"><em class="pj">json</em></strong></span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="baaa">You are now ready to access ECR using the following command, provide <strong class="kx jh">region </strong>and <strong class="kx jh">account id</strong> details.</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="3ed2">aws ecr get-login-password  --region <strong class="ok jh">region</strong> | docker login --username AWS --password-stdin <strong class="ok jh">aws_account_id.</strong>dkr.ecr.<strong class="ok jh">region</strong>.amazonaws.com</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="272c">You should see<strong class="kx jh"> âLogin Succeededâ </strong>on the console if everything goes well.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="1e48">You can now push your image on the AWS registry.<br/>First, create a repository.</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="8743">aws ecr create-repository --repository-name price_estimator_api</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="a329">Tag your image in order to push on the registry.</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="db4d">docker tag price_api:latest <strong class="ok jh">aws_account_id</strong>.dkr.ecr.<strong class="ok jh">region</strong>.amazonaws.com/price_estimator_api</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="d60c">Finally, run the command to push the image on ECR.</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="3542">docker push <strong class="ok jh">aws_account_id</strong>.dkr.ecr.<strong class="ok jh">region</strong>.amazonaws.com/price_estimator_api</span></pre><h2 class="nr ls jg bm lt ns nt nu lx nv nw nx mb le ny nz md li oa ob mf lm oc od mh oe ga" id="891f">Deploy on EC2</h2><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="fc30">After pushing the docker image to AWS ECR, we are now ready to create Amazon EC2 instance which can serve your web application. AWS offers many instances in the free tier, I have chosen a Linux instance in this case (you can use other instances as well but do remember to change the configuration accordingly).</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="b3f2"><em class="pj">i ) Go to Amazon Console; select Amazon Linux EC2 instance.</em></p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="5b67"><em class="pj">ii) Choose general purpose t2.micro instance type, for example.</em></p><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm rc"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/0*_u1WW-CiD9pCu2Ej.png 640w, https://miro.medium.com/max/720/0*_u1WW-CiD9pCu2Ej.png 720w, https://miro.medium.com/max/750/0*_u1WW-CiD9pCu2Ej.png 750w, https://miro.medium.com/max/786/0*_u1WW-CiD9pCu2Ej.png 786w, https://miro.medium.com/max/828/0*_u1WW-CiD9pCu2Ej.png 828w, https://miro.medium.com/max/1100/0*_u1WW-CiD9pCu2Ej.png 1100w, https://miro.medium.com/max/1400/0*_u1WW-CiD9pCu2Ej.png 1400w"/><img alt="" class="ce my mz c" height="346" loading="lazy" role="presentation" width="700"/></picture></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="5a88"><em class="pj">iii) Change the security settings by adding rules using custom TCP as type and port as 5000 (we exposed that port of the API) and click on review and launch the instance. These configurations are necessary for our web application to run.</em></p><figure class="mp mq mr ms gx mt gl gm paragraph-image"><div class="mu mv do mw ce mx" role="button" tabindex="0"><div class="gl gm rd"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/0*Ki9YCYS7P6ka9z1F.png 640w, https://miro.medium.com/max/720/0*Ki9YCYS7P6ka9z1F.png 720w, https://miro.medium.com/max/750/0*Ki9YCYS7P6ka9z1F.png 750w, https://miro.medium.com/max/786/0*Ki9YCYS7P6ka9z1F.png 786w, https://miro.medium.com/max/828/0*Ki9YCYS7P6ka9z1F.png 828w, https://miro.medium.com/max/1100/0*Ki9YCYS7P6ka9z1F.png 1100w, https://miro.medium.com/max/1400/0*Ki9YCYS7P6ka9z1F.png 1400w"/><img alt="" class="ce my mz c" height="292" loading="lazy" role="presentation" width="700"/></picture></div></div></figure><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="771d"><em class="pj">iv) Create a new key pair by selecting from the dropdown â</em>Create a new key pair<em class="pj">â, provide a name for the key pair, and download it.</em></p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="032b">A key pair, consisting of a private key and a public key, is a set of security credentials that you use to prove your identity when connecting to an instance.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="96ba">You should able to see the instance running.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="0035">You downloaded the key pair, so a <code class="fp oh oi oj ok b">.pem</code> key. Suppose we gave the name <code class="fp oh oi oj ok b">priceestimator.pem</code> , we can use such a file to log on to the EC2 by using a secure ssh connection.</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="a260">ssh -i priceestimator.pem ec2-user@<strong class="ok jh">ec2-18-221-11-226.us-east-2.compute.amazonaws.com</strong></span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="54cf">One logged in, we install the docker on the EC2, configure AWS access to give rights to the machine to access our docker image, and pull the docker container to the machine.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="cf0c">AWS configuration starts as above,</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="18de">aws configure</span><span class="ga nr ls jg ok b dm qx oq l or os" id="d0a8">AWS Access Key ID [None]: <strong class="ok jh"><em class="pj">AKIAIOSFODNN7EXAMPLE</em></strong><br/>AWS Secret Access Key [None]:<strong class="ok jh"><em class="pj">wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY</em></strong><br/>Default region name [None]: <strong class="ok jh"><em class="pj">eu-west-3</em></strong><br/>Default output format [None]:<strong class="ok jh"><em class="pj">json</em></strong></span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="9cb6">Then we run the following commands to add ec2 user to perform docker commands in Linux machine.</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="09ed">sudo groupadd docker</span><span class="ga nr ls jg ok b dm qx oq l or os" id="3f7f">sudo gpasswd -a ${USER} docker</span><span class="ga nr ls jg ok b dm qx oq l or os" id="86e4">sudo service docker restart</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="53bb">Exit the instance and ssh into the EC2 instance again.</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="9810">ssh -i priceestimator.pem ec2-user@<strong class="ok jh">ec2-18-221-11-226.eu-west-3.compute.amazonaws.com</strong></span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="5b39">Log into the Amazon ECR registry:</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="1a50">aws ecr get-login --region <strong class="ok jh">region</strong> --no-include-email</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="76c5">output</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="b4d1">docker login -u AWS -p &lt;password&gt; -e none https://&lt;aws_account_id&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="4352">Copy the output from the above and run it in the command line. Once you are successfully logged into AWS ECR, you can see âLogin Succeededâ in the console.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="8c39">Pull the docker image from AWS ECR on the EC2.</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="ee6d">docker pull <strong class="ok jh">aws_account_id</strong>.dkr.ecr.<strong class="ok jh">region</strong>.amazonaws.com/price_estimator_api:latest</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="bb87">Run the docker container in the Linux Machine</p><pre class="mp mq mr ms gx om bs on oo dz ok"><span class="ga nr ls jg ok b dm op oq l or os" id="6fba">docker run -p 5000:5000 <strong class="ok jh">aws_account_id</strong>.dkr.ecr.<strong class="ok jh">region</strong>.amazonaws.com/price_estimator_api</span></pre><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="0c01">Finally, we can get the IPv4 Public IP from the instance details page and add port 5000 while launching it in the browser. This will show the API running on EC2. <br/>Now you can substitute such an IP address with a more human-readable URL.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="271d">Enjoy!</p></div><div class="o dx nf ng ii nh" role="separator"><span class="ni fl ci nj nk nl"></span><span class="ni fl ci nj nk nl"></span><span class="ni fl ci nj nk"></span></div><div class="iz ja jb jc jd"><h1 class="lr ls jg bm lt lu nm lw lx ly nn ma mb km no kn md kp np kq mf ks nq kt mh mi ga" id="0aae">4. Maintenance</h1><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="a893">And finally the dessert: maintaining the deployed app is crucial. A change in data distribution may result in no predictive power of your model.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="fdc9">Now your model works fine, lucky you. You are happy and ready to repeat the story for another client and another model.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="b0a6">However, the real estate agency starts to get some houses to sell in a very different location. They use your model and they find your estimate completely wrong! They are angry at your company, your boss starts to tell you off about the awful job you have done.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="8f60">How would you handle this?</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="7dc5">Fortunately, by acting as you have done you can easily deploy a new model, by training on new data and make your model more accurate on the new data distribution. Letâs see how.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="9dc6">What we have done previously is not lost. We can load the current model and use it as a starting point for a new train. We make leverage of previously learnt weights and we simply train our model on new data. If necessary (you want to completely change your model, for some reason) you can also develop a new model. If you coded properly, nothing should change in the whole pipeline.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="c878"><strong class="kx jh">Load the current model</strong> <strong class="kx jh">as pretrained</strong> in <code class="fp oh oi oj ok b">config.json</code>. Now you can relaunch the training script and get the newly trained model. Change the save model name to keep versioning.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="e443"><strong class="kx jh">Save the new model </strong>As before, we save the model in the folder the API is going to read. We can add the date-time reference in the naming convention in order to keep track of versions.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="3cdf"><strong class="kx jh">Modify the Dockerfile </strong>Since we version our app, we modify the <code class="fp oh oi oj ok b">Dockerfile</code> to get the right model version to be deployed.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="2a89">Finally, <strong class="kx jh">push the Docker image</strong> and make it run as above.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="d3de"><em class="pj">NOTE: </em>Itâs usually advisable to write the deploy part as a pipeline, that starts automatically at every push on some git repository. All git control systems offer the possibility to register safely some repository environment variables. One can set some secret AWS credentials there and automatise this part. For more information, look at the following tutorial, for example.</p><div class="pl pm gt gv pn po"><a href="https://support.atlassian.com/bitbucket-cloud/docs/get-started-with-bitbucket-pipelines/" rel="noopener ugc nofollow" target="_blank"><div class="pp o fr"><div class="pq o da dx en pr"><h2 class="bm jh dm bo fs ps fu fv pt fx fz jf ga">Get started with Bitbucket Pipelines | Bitbucket Cloud | Atlassian Support</h2><div class="pu l"><h3 class="bm b dm bo fs ps fu fv pt fx fz cn">Bitbucket Pipelines is an integrated CI/CD service built into Bitbucket Cloud. Learn how to set up Pipelines.</h3></div><div class="pv l"><p class="bm b hi bo fs ps fu fv pt fx fz cn">support.atlassian.com</p></div></div></div></a></div></div><div class="o dx nf ng ii nh" role="separator"><span class="ni fl ci nj nk nl"></span><span class="ni fl ci nj nk nl"></span><span class="ni fl ci nj nk"></span></div><div class="iz ja jb jc jd"><h1 class="lr ls jg bm lt lu nm lw lx ly nn ma mb km no kn md kp np kq mf ks nq kt mh mi ga" id="ebae">Conclusions</h1><p class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq iz ga" id="470e">First of all, let me congratulate you if you have read till here! This post has become a little longer than I expected.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="a45c">To sum up, I tried to summarise, working through a concrete example, how the typical data science project develops, to my experience. I would like to warn you: this is not the complete story. There are a lot of points I missed and neglected, a lot of caveats, a lot of different requests, etc.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="7f96">For instance, another possibility might be to not bother at all with containers and services and convert our model in some other language, easily runnable online. <br/>For a web app, for example, one may convert the model in JavaScript (making use for instance of TensorFlowJS or TorchJS running models on a browser) and then build a website to be hosted on some server. This is an example of a specific case. Indeed, this is accessible through a website, but what if you need an app to access this? Or some other non-human service?</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="e58e">Docker is a more general and widely used method, this is why I have chosen to present it here.<br/>Hence, without being complete, this post aimed to illustrate â in a schematic way â the lifecycle of a machine learning project.<br/>I hope this can be useful both to junior data scientists, often feeling lost in this wide world, and to more expert figures that can also give me some hint about the points I surely forgot.</p><p class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq iz ga" id="9906">I hope you enjoyed reading this!</p><blockquote class="re"><p class="rf rg jg bm rh ri rj rk rl rm rn lq cn" id="b0c9">IMPORTANT: I publish this post also to get suggestions, to discuss and to be made aware of points of weakness in my coding. Please, signal any mistakes/reduntant code! ð«</p></blockquote><p class="pw-post-body-paragraph kv kw jg kx b ky ro kh la lb rp kk ld le rq lg lh li rr lk ll lm rs lo lp lq iz ga" id="3a7a">ð¤¯ <strong class="kx jh"><em class="pj">Have you seen what happens if you click the âclapâ button multiple times?</em></strong></p></div></div></section></div></div></article>