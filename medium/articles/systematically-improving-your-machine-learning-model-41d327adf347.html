<article class="meteredContent"><div class="l"><div class="gg gh gi gj gk gl gm ce gn ch l"></div><div class="l"><header class="pw-post-byline-header go gp gq gr gs gt gu gv gw gx l"><div class="o gy u"><div class="o"><div class="fj l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://kurtispykes.medium.com/?source=post_page-----41d327adf347--------------------------------" rel="noopener follow"><div class="l do"><img alt="Kurtis Pykes" class="l ch fl gz ha fp" height="48" loading="lazy" src="https://miro.medium.com/fit/c/96/96/1*fbRxcMp7shL72EVtrl33Rg.png" width="48"/><div class="fk fl l gz ha fo aq"></div></div></a></div><div class="l"><div class="pw-author bm b dm dn ga"><div class="hb o hc"><div><div aria-hidden="false" class="ci"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://kurtispykes.medium.com/?source=post_page-----41d327adf347--------------------------------" rel="noopener follow">Kurtis Pykes</a></div></div><div class="hd he hf hg hh d"><span><a class="bm b hi bo hj hk hl hm hn ho hp bd bz hq hr hs cd cf cg ch ci cj" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5ba760786877&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsystematically-improving-your-machine-learning-model-41d327adf347&amp;user=Kurtis+Pykes&amp;userId=5ba760786877&amp;source=post_page-5ba760786877----41d327adf347---------------------follow_byline-----------" rel="noopener follow">Follow</a></span></div></div></div><div class="o ao ht"><p class="pw-published-date bm b bn bo cn"><span>Nov 19, 2020</span></p><div aria-hidden="true" class="hu ci"><span aria-hidden="true" class="l"><span class="bm b bn bo cn">·</span></span></div><div class="pw-reading-time bm b bn bo cn">9 min read</div><div aria-hidden="true" class="hu ci"><span aria-hidden="true" class="l"><span class="bm b bn bo cn">·</span></span></div><div class="hx l"><div aria-hidden="false" class="l"><button class="l dz hv bb"><div class="j i d"><div><div aria-hidden="false" class="ci"><svg fill="none" height="20" viewbox="0 0 20 20" width="20"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div><div class="h k hy hz ia"><svg class="hw" fill="none" height="20" viewbox="0 0 20 20" width="20"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg><p class="bm b bn bo cn">Member-only</p></div></button></div></div></div></div></div><div class="o ao"><div class="h k ib ic id"><div class="ie l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on twitter" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ie l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on facebook" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ie l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on linkedin" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l fr"><div><div aria-hidden="false" class="ci"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8" fill-rule="evenodd"></path></svg></span></button></div></div></div><div class="ih o ao"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F41d327adf347&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsystematically-improving-your-machine-learning-model-41d327adf347&amp;source=--------------------------bookmark_header-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="au de aw ax ay az ba if bc hv ij ik il"><svg aria-label="Add to list bookmark button" class="ii" fill="none" height="25" viewbox="0 0 25 25" width="25"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></button></a></span></div></div><div class="ck im"><div><div aria-hidden="false" class="ci"></div></div></div></div></div><div class="in io ip j i d"><div class="fj l"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F41d327adf347&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsystematically-improving-your-machine-learning-model-41d327adf347&amp;source=--------------------------bookmark_header-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="au de aw iq ay az ba ir bc hv cd o ao is it il"><svg aria-label="Add to list bookmark button" class="ii" fill="none" height="25" viewbox="0 0 25 25" width="25"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg><p class="bm b bn bo cn">Save</p></button></a></span></div><div class="iu l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on twitter" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="iu l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on facebook" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="iu l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on linkedin" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l fr"><div><div aria-hidden="false" class="ci"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></header><span class="l"></span><section><div><div class="fo as ja jb jc jd"></div><div class="je jf jg jh ji"><div class=""><h1 class="pw-post-title jj jk jl bm jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ga" id="ff7c">Systematically Improving Your Machine Learning Model</h1></div><div class=""><h2 class="pw-subtitle-paragraph ki jk jl bm b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz cn" id="5b21">The Machine Learning Inevitables</h2></div><figure class="lb lc ld le gx lf gl gm paragraph-image"><div class="lg lh do li ce lj" role="button" tabindex="0"><div class="gl gm la"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/0*U21Mp3goRwlL4ZUj 640w, https://miro.medium.com/max/720/0*U21Mp3goRwlL4ZUj 720w, https://miro.medium.com/max/750/0*U21Mp3goRwlL4ZUj 750w, https://miro.medium.com/max/786/0*U21Mp3goRwlL4ZUj 786w, https://miro.medium.com/max/828/0*U21Mp3goRwlL4ZUj 828w, https://miro.medium.com/max/1100/0*U21Mp3goRwlL4ZUj 1100w, https://miro.medium.com/max/1400/0*U21Mp3goRwlL4ZUj 1400w"/><img alt="" class="ce lk ll c" height="467" loading="eager" role="presentation" width="700"/></picture></div></div><figcaption class="lm bl gn gl gm ln lo bm b bn bo cn">Photo by <a class="au lp" href="https://unsplash.com/@grstocks?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">GR Stocks</a> on <a class="au lp" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="d7b8">When working on a Machine learning task, it’s highly likely the process will be extremely iterative due to the nature of Machine Learning, which involves a computer learning without being explicitly programmed.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="2c05">Similar to how we work on mock exams to improve ourselves in an attempt to achieve higher grades on the real exam, we use mock instances — better known as validation data — to infer how we can expect to do when the model is placed in the real world.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="104c">If you think of how we improve by using mock exams, it generally consist of identifying what we have done wrong and revisit those subjects. Likewise, if we could identify the areas in which our machine learning models makes errors, we can revisit those places and make some adjustments to improve our model “mock score” in turn implying we will achieve a better result when the model meets the real world.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="14cf">Therefore, before we can begin to understand the type of errors our Machine Learning model is making we ought to have made some sort of attempt at trying to predict something already — we need to take the exam. Hence, many experienced practitioners would advise beginning practitioners to start with a simple algorithm that can be implemented quickly and tested on validation data.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="dff0">This implementation does not have to be extremely great. As long as we are able to make predictions and gain some sort of insight into our data we can begin to improve our model systematically.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="7f23">An example of a quick and dirty implementation is the beginning of my Twitter Sentiment Analysis project.</p><blockquote class="mm mn mo"><p class="lq lr mp ls b lt lu km lv lw lx kp ly mq ma mb mc mr me mf mg ms mi mj mk ml je ga" id="15df"><strong class="ls jm">Note</strong>: For the rest of this article, I will be making references to this project. Please familiarise yourself with what was done by reading the article below before carrying on with this post.</p></blockquote><div class="mt mu gt gv mv mw"><a href="/predicting-tweet-sentiment-with-machine-learning-3599c8add259" rel="noopener follow" target="_blank"><div class="mx o fr"><div class="my o da dx en mz"><h2 class="bm jm dm bo fs na fu fv nb fx fz jk ga">Predicting Tweet Sentiment with Machine Learning</h2><div class="nc l"><h3 class="bm b dm bo fs na fu fv nb fx fz cn">Sentiment analysis on Tweets</h3></div><div class="nd l"><p class="bm b hi bo fs na fu fv nb fx fz cn">towardsdatascience.com</p></div></div><div class="ne l"><div class="nf l ng nh ni ne nj lk mw"></div></div></div></a></div><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="5828">In this project, the aim is to predict whether a tweet is about a disaster or not given the tweet, location, and keyword (although not all tweets are accompanied by location or keyword).</p><blockquote class="nk"><p class="nl nm jl bm nn no np nq nr ns nt ml cn" id="8a70">“Let evidence guide you on where to spend your time rather than use gut feeling which is often wrong” — Andrew Ng</p></blockquote><h2 class="nu nv jl bm nw nx ny nz oa ob oc od oe lz of og oh md oi oj ok mh ol om on oo ga" id="9657">Learning Curves</h2><p class="pw-post-body-paragraph lq lr jl ls b lt op km lv lw oq kp ly lz or mb mc md os mf mg mh ot mj mk ml je ga" id="dce6">In machine learning, a learning<strong class="ls jm"> </strong>curve (or training curve) shows the validation and training score of an estimator for varying numbers of training samples. It is a tool to find out how much a machine learning model benefits from adding more training data and whether the estimator suffers more from a variance error or a bias error (<em class="mp">Source</em>: <a class="au lp" href="https://en.wikipedia.org/wiki/Learning_curve_(machine_learning)" rel="noopener ugc nofollow" target="_blank"><strong class="ls jm">Wikipedia</strong></a>).</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="f4e2">Learning Curves are extremely useful for sanity checks on whether your Machine Learning algorithm is working correctly or if you want to improve the performance of your machine learning algorithm — We will be applying a learning curve to the classifier we used for Twitter sentiment classification at some stage to better understand better our model.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="e33f">Given we have a training and test set, it’s important to understand how the classifiers perform depending on the size of the training set. Therefore, learning curves are a plot of the model's performance which is often denoted as cost against the size of the training and test set.</p><blockquote class="mm mn mo"><p class="lq lr mp ls b lt lu km lv lw lx kp ly mq ma mb mc mr me mf mg ms mi mj mk ml je ga" id="ad1e"><strong class="ls jm">Note</strong>: I prefer to do all analysis and exploratory work in a Juypter notebook as I’ve done to generate the outputs shown in Figure 1. See the Github Channel for.</p></blockquote><figure class="lb lc ld le gx lf gl gm paragraph-image"><div class="lg lh do li ce lj" role="button" tabindex="0"><div class="gl gm ou"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*A1W_-tQKKYKBUT-dVpWmXg.png 640w, https://miro.medium.com/max/720/1*A1W_-tQKKYKBUT-dVpWmXg.png 720w, https://miro.medium.com/max/750/1*A1W_-tQKKYKBUT-dVpWmXg.png 750w, https://miro.medium.com/max/786/1*A1W_-tQKKYKBUT-dVpWmXg.png 786w, https://miro.medium.com/max/828/1*A1W_-tQKKYKBUT-dVpWmXg.png 828w, https://miro.medium.com/max/1100/1*A1W_-tQKKYKBUT-dVpWmXg.png 1100w, https://miro.medium.com/max/1400/1*A1W_-tQKKYKBUT-dVpWmXg.png 1400w"/><img alt="" class="ce lk ll c" height="234" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lm bl gn gl gm ln lo bm b bn bo cn"><strong class="bm ov">Figure 1</strong>: Learning Curve on the <a class="au lp" href="/predicting-tweet-sentiment-with-machine-learning-3599c8add259" rel="noopener" target="_blank">Twitter Sentiment Data</a> (Image by Author)</figcaption></figure><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="cd33">From the learning curve, we can see our model is not doing particularly well on the training data and is doing severely bad on the validation data. The large gap between the training score and validation score suggests there is a large variance between the model predictions on training and validation data. However, since this is a Kaggle dataset, adding more data isn’t necessarily something that is straightforward (though it may be useful in the real-world to overcome this problem).</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="d3a3">However, after some analysis of my data I realized that the preprocessing I had done was the error. I attempted to add the 3 text columns ( <code class="fp ow ox oy oz b">text</code>, <code class="fp ow ox oy oz b">location</code>, <code class="fp ow ox oy oz b">keyword</code>) together to make one column containing all of our text, but the <code class="fp ow ox oy oz b">location</code> and <code class="fp ow ox oy oz b">keyword</code> columns have missing values, so when I added those columns to the <code class="fp ow ox oy oz b">text</code> column without first dealing with the missing values, the function deleted a number of tweets — see <em class="mp">Figure 2</em>.</p><pre class="lb lc ld le gx pa bs pb pc dz oz"><span class="ga nu nv jl oz b dm pd pe l pf pg" id="0255"># read train data<br/>df = pd.read_csv("../inputs/train.csv")<br/># shuffle data<br/>df = df.sample(frac=1, random_state=42).reset_index(drop=True)<br/># create new column "all_text"<br/>df["all_text"] = df["text"] + df["keyword"] + df["location"]<br/># split into features and labels<br/>X = df.drop(["text", "keyword", "location", "target"], axis=1)<br/>y = df["target"]</span><span class="ga nu nv jl oz b dm ph pe l pf pg" id="67de"># process tweets<br/>X["all_text"] = X["all_text"].apply(process_tweet)<br/>X.head() </span></pre><figure class="lb lc ld le gx lf gl gm paragraph-image"><div class="gl gm pi"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 353px" srcset="https://miro.medium.com/max/640/1*me6Cnv6yjYIy0aZi6kw19Q.png 640w, https://miro.medium.com/max/720/1*me6Cnv6yjYIy0aZi6kw19Q.png 720w, https://miro.medium.com/max/750/1*me6Cnv6yjYIy0aZi6kw19Q.png 750w, https://miro.medium.com/max/786/1*me6Cnv6yjYIy0aZi6kw19Q.png 786w, https://miro.medium.com/max/828/1*me6Cnv6yjYIy0aZi6kw19Q.png 828w, https://miro.medium.com/max/1100/1*me6Cnv6yjYIy0aZi6kw19Q.png 1100w, https://miro.medium.com/max/706/1*me6Cnv6yjYIy0aZi6kw19Q.png 706w"/><img alt="" class="ce lk ll c" height="171" loading="lazy" role="presentation" width="353"/></picture></div><figcaption class="lm bl gn gl gm ln lo bm b bn bo cn"><strong class="bm ov">Figure 2</strong>: Error way of adding columns together since some columns have empty values. This will affect how the model learns since it has fewer data to learn from. (Image by author)</figcaption></figure><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="8523">Therefore, it is likely we have deleted too much data which is making it difficult for the model to learn well. Hence, we can easily repeat this process but instead correct how we add all the columns together by filling the missing values with a “none” marker — see <em class="mp">Figure 3</em> for the result.</p><pre class="lb lc ld le gx pa bs pb pc dz oz"><span class="ga nu nv jl oz b dm pd pe l pf pg" id="d84e"># new empty df <br/>X_new = pd.DataFrame()<br/># new features with correctly joined columns<br/>X_new["all_text"] = df["text"] + df["keyword"].fillna("none") + df["location"].fillna("none")<br/># process tweets<br/>X_new["all_text"] = X_new["all_text"].apply(process_tweet)<br/>X_new.head()</span></pre><figure class="lb lc ld le gx lf gl gm paragraph-image"><div class="gl gm pj"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 322px" srcset="https://miro.medium.com/max/640/1*qsQnaqJZ1RLa5qQHgESj_w.png 640w, https://miro.medium.com/max/720/1*qsQnaqJZ1RLa5qQHgESj_w.png 720w, https://miro.medium.com/max/750/1*qsQnaqJZ1RLa5qQHgESj_w.png 750w, https://miro.medium.com/max/786/1*qsQnaqJZ1RLa5qQHgESj_w.png 786w, https://miro.medium.com/max/828/1*qsQnaqJZ1RLa5qQHgESj_w.png 828w, https://miro.medium.com/max/1100/1*qsQnaqJZ1RLa5qQHgESj_w.png 1100w, https://miro.medium.com/max/644/1*qsQnaqJZ1RLa5qQHgESj_w.png 644w"/><img alt="" class="ce lk ll c" height="173" loading="lazy" role="presentation" width="322"/></picture></div><figcaption class="lm bl gn gl gm ln lo bm b bn bo cn"><strong class="bm ov">Figure 3</strong>: We have corrected how we join the columns by filling the empty columns with “none”. Now you see the difference between this and Figure 2. (Image by Author)</figcaption></figure><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="d9bb">But the all-important question is did this slight change improve our model? We can answer this question by checking in with our learning curve once again.</p><figure class="lb lc ld le gx lf gl gm paragraph-image"><div class="lg lh do li ce lj" role="button" tabindex="0"><div class="gl gm pk"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*qP2kqGdrqD-LgkPMu2GiBg.png 640w, https://miro.medium.com/max/720/1*qP2kqGdrqD-LgkPMu2GiBg.png 720w, https://miro.medium.com/max/750/1*qP2kqGdrqD-LgkPMu2GiBg.png 750w, https://miro.medium.com/max/786/1*qP2kqGdrqD-LgkPMu2GiBg.png 786w, https://miro.medium.com/max/828/1*qP2kqGdrqD-LgkPMu2GiBg.png 828w, https://miro.medium.com/max/1100/1*qP2kqGdrqD-LgkPMu2GiBg.png 1100w, https://miro.medium.com/max/1400/1*qP2kqGdrqD-LgkPMu2GiBg.png 1400w"/><img alt="" class="ce lk ll c" height="230" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lm bl gn gl gm ln lo bm b bn bo cn"><strong class="bm ov">Figure 4</strong>: Fixed data deletion error</figcaption></figure><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="f048"><strong class="ls jm">You bet it improved the model!</strong> The model is performing much better on the training and the cross-validation data. However, there is still a large variance between the scores on our training data and our cross-validation sets. At this point, you’ll see many Kagglers rush to the more powerful models. This is not necessarily bad, but there may be times where you have limited resources in the real-world and you need a model that can work in production, which is not the case for many of the winning solutions on Kaggle.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="c6d6">Instead, we will first perform something known as <em class="mp">error analysis</em> to get a better look at some things that we can adjust to improve our models fit on new instances.</p><blockquote class="mm mn mo"><p class="lq lr mp ls b lt lu km lv lw lx kp ly mq ma mb mc mr me mf mg ms mi mj mk ml je ga" id="bd89"><strong class="ls jm">Note</strong>: The small preprocessing change we made took our public leaderboard score from <code class="fp ow ox oy oz b">0.71008</code> to <code class="fp ow ox oy oz b">0.79374</code>.</p></blockquote><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="0c62">For a more in-depth tutorial about Learning curves, I recommend viewing “<a class="au lp" href="https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/" rel="noopener ugc nofollow" target="_blank"><strong class="ls jm"><em class="mp">Learning Curves for Diagnosing Machine Learning Performance</em></strong></a>” by Jason Brownlee at Machine Learning Mastery.</p><h2 class="nu nv jl bm nw nx pl nz oa ob pm od oe lz pn og oh md po oj ok mh pp om on oo ga" id="38f9">Error Analysis</h2><p class="pw-post-body-paragraph lq lr jl ls b lt op km lv lw oq kp ly lz or mb mc md os mf mg mh ot mj mk ml je ga" id="fa28">Error analysis is a process where we manually identify the examples in our validation data that our model predicted incorrectly. The idea of this is to identify systematic trends based on the errors that our model made.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="52eb">To provide a similar scenario of error analysis, we can use our exam preparation example we used above. Say we have just completed a math mock exam and now we are marking our work and see we got 40/60. We would now go through the paper and see what it was we got wrong and mark them into certain categories:</p><ul class=""><li class="pq pr jl ls b lt lu lw lx lz ps md pt mh pu ml pv pw px py ga" id="13b9">Linear Algebra — 60%</li><li class="pq pr jl ls b lt pz lw qa lz qb md qc mh qd ml pv pw px py ga" id="331e">Statistics — 25%</li><li class="pq pr jl ls b lt pz lw qa lz qb md qc mh qd ml pv pw px py ga" id="b22d">Calculus — 15%</li></ul><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="58ed">The table above informs us that among the 20 errors that we made, 15% of those errors were to do with calculus, 25% were to do with Statistics, and 60% was to do with Linear Algebra. Based on this information what would you now seek to improve first?</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="7761">Hopefully, you said you would spend your time trying to improve your Linear Algebra skills because if you improve that, that would add a more significant boost to your overall score on the new mock paper than if you were to improve statistics or calculus first.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="384a">Therefore in a Machine Learning setting, you could say error analysis is what provides direction for where to go next when you are attempting to improve your machine learning model. You simply identify the systematic trends in the errors the model made on the validation data (i.e. Tweets with hashtags were always classified a certain way, or tweets with URLs were always classified incorrectly).</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="64ab">Let’s do some error analysis using our Twitter Sentiment Data. The first thing I will do is take 100 misclassified instances (therefore 20 from each fold). Next, I will create a Dataframe which I will save as a <strong class="ls jm">CSV</strong> file containing the original tweet, the processed tweet, the actual score, and the predicted score.</p><figure class="lb lc ld le gx lf gl gm paragraph-image"><div class="lg lh do li ce lj" role="button" tabindex="0"><div class="gl gm qe"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*8eBircRJBWC0X80PcbhaVA.png 640w, https://miro.medium.com/max/720/1*8eBircRJBWC0X80PcbhaVA.png 720w, https://miro.medium.com/max/750/1*8eBircRJBWC0X80PcbhaVA.png 750w, https://miro.medium.com/max/786/1*8eBircRJBWC0X80PcbhaVA.png 786w, https://miro.medium.com/max/828/1*8eBircRJBWC0X80PcbhaVA.png 828w, https://miro.medium.com/max/1100/1*8eBircRJBWC0X80PcbhaVA.png 1100w, https://miro.medium.com/max/1400/1*8eBircRJBWC0X80PcbhaVA.png 1400w"/><img alt="" class="ce lk ll c" height="257" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lm bl gn gl gm ln lo bm b bn bo cn"><strong class="bm ov">Figure 5:</strong> Misclassified Tweets (Image by Author)</figcaption></figure><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="f9a2"><strong class="ls jm"><em class="mp">Please note that there may be some offensive language used in some of the tweets.</em></strong></p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="3c37">After that, I will manually examine the errors and categorize them into separate headings. We do this by manually examining the errors based on various factors such as the type of tweet (i.e. news report, experience, opinion), and the actual errors being made that we believe if corrected for can improve the algorithm (i.e. metaphorical errors, spelling mistakes, sarcasm).</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="5e01">Fortunately, I’ve done this task as an example with 50 randomly selected misclassified instances (ideally you may want to do it on more, but this is just an example) based on the type of tweet. Here are my findings:</p><ul class=""><li class="pq pr jl ls b lt lu lw lx lz ps md pt mh pu ml pv pw px py ga" id="618d">Other— 13 (26 %)</li><li class="pq pr jl ls b lt pz lw qa lz qb md qc mh qd ml pv pw px py ga" id="8b7a">Opinion — 3 (6%)</li><li class="pq pr jl ls b lt pz lw qa lz qb md qc mh qd ml pv pw px py ga" id="8706">Mislabelled —16 (32%)</li><li class="pq pr jl ls b lt pz lw qa lz qb md qc mh qd ml pv pw px py ga" id="7937">Experience — 7 (14%)</li><li class="pq pr jl ls b lt pz lw qa lz qb md qc mh qd ml pv pw px py ga" id="9692">News — 9 (18%)</li></ul><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="4059">There are 32% mislabeled examples from the 50 random misclassified samples that we took. Meaning, they do not come across as a disaster and they are labelled as a disaster or they are not a disaster and they are labelled disaster, from my own opinion.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="86c1">For example…</p><blockquote class="mm mn mo"><p class="lq lr mp ls b lt lu km lv lw lx kp ly mq ma mb mc mr me mf mg ms mi mj mk ml je ga" id="6266">“I liked a @YouTube video <a class="au lp" href="http://t.co/z8Cp77lVza" rel="noopener ugc nofollow" target="_blank">http://t.co/z8Cp77lVza</a> Boeing 737 takeoff in snowstorm. HD cockpit view + ATC audio — Episode 18snowstormPorthcawl”</p></blockquote><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="0283">…is labelled as being a disaster, but a human wouldn’t instantly class this as <strong class="ls jm">NOT</strong> being a disaster.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="7757">Another example is…</p><blockquote class="mm mn mo"><p class="lq lr mp ls b lt lu km lv lw lx kp ly mq ma mb mc mr me mf mg ms mi mj mk ml je ga" id="e70a">“@PrablematicLA @Adweek I’m actually currently dressed for a snowstorm…despite being in the middle of a Texas summer. Thanks office A/C.snowstormAustin, TX”.</p></blockquote><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="b596">This is marked as being a disaster but we can easily tell it is not necessarily a disaster. It may be a disaster for the person making the tweet but in the general publics eye this is not a disaster that one would be concerned about.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="aa18">The data we are using is a Kaggle Dataset so going back to relabel instances won’t necessarily be beneficial for us since the test data we have no access to would also probably be labelled accordingly. However, in a real-world scenario I’d definitely seek clarity on the definition of the term <strong class="ls jm">disaster </strong>in the context that<strong class="ls jm"> </strong>we are using it. Based upon the definition, we may have to relabel the data again or look at the 2nd types of tweets our algorithm made errors on and begin working on improving our algorithms ability on those.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="f1d9">Error analysis is very beneficial for determining what sort of errors our algorithm is making, hence providing us with good insight to what we can improve to provide us with the most significant improvement to our model. On the other hand, Error analysis is incapable of distinguishing whether something like stemming or how we vectorize the text is beneficial to the final solution, and the only solution is to try it and evaluate the change on the evaluation metric.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="029a">With that being said, let’s attempt to use <a class="au lp" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf#:~:text=In%20information%20retrieval%2C%20tf%E2%80%93idf,in%20a%20collection%20or%20corpus." rel="noopener ugc nofollow" target="_blank">TF-IDF</a> to convert our text into vectors.</p><figure class="lb lc ld le gx lf gl gm paragraph-image"><div class="lg lh do li ce lj" role="button" tabindex="0"><div class="gl gm qf"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*1mQvb_fW_CXtqTCQD5pVDw.png 640w, https://miro.medium.com/max/720/1*1mQvb_fW_CXtqTCQD5pVDw.png 720w, https://miro.medium.com/max/750/1*1mQvb_fW_CXtqTCQD5pVDw.png 750w, https://miro.medium.com/max/786/1*1mQvb_fW_CXtqTCQD5pVDw.png 786w, https://miro.medium.com/max/828/1*1mQvb_fW_CXtqTCQD5pVDw.png 828w, https://miro.medium.com/max/1100/1*1mQvb_fW_CXtqTCQD5pVDw.png 1100w, https://miro.medium.com/max/1400/1*1mQvb_fW_CXtqTCQD5pVDw.png 1400w"/><img alt="" class="ce lk ll c" height="151" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lm bl gn gl gm ln lo bm b bn bo cn"><strong class="bm ov">Figure 7:</strong> Score with TF-IDF vectorization</figcaption></figure><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="3be8">This didn’t improve our score of <code class="fp ow ox oy oz b">0.79374</code> so I would not continue with TF-IDF, or I may try tf-idf without stemming, etc.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="01b5">If you enjoyed this post, you’d also like:</p><div class="mt mu gt gv mv mw"><a href="/using-machine-learning-to-detect-fraud-f204910389cf" rel="noopener follow" target="_blank"><div class="mx o fr"><div class="my o da dx en mz"><h2 class="bm jm dm bo fs na fu fv nb fx fz jk ga">Using Machine Learning To Detect Fraud</h2><div class="nc l"><h3 class="bm b dm bo fs na fu fv nb fx fz cn">The beginning of an End-to-End Machine Learning Project</h3></div><div class="nd l"><p class="bm b hi bo fs na fu fv nb fx fz cn">towardsdatascience.com</p></div></div><div class="ne l"><div class="qg l ng nh ni ne nj lk mw"></div></div></div></a></div><div class="mt mu gt gv mv mw"><a href="/how-to-make-your-data-science-projects-stand-out-b91d3861a885" rel="noopener follow" target="_blank"><div class="mx o fr"><div class="my o da dx en mz"><h2 class="bm jm dm bo fs na fu fv nb fx fz jk ga">How To Make Your Data Science Projects Stand Out</h2><div class="nc l"><h3 class="bm b dm bo fs na fu fv nb fx fz cn">Create an effective README</h3></div><div class="nd l"><p class="bm b hi bo fs na fu fv nb fx fz cn">towardsdatascience.com</p></div></div><div class="ne l"><div class="qh l ng nh ni ne nj lk mw"></div></div></div></a></div><div class="mt mu gt gv mv mw"><a href="/getting-started-with-sentiment-analysis-731531ec880d" rel="noopener follow" target="_blank"><div class="mx o fr"><div class="my o da dx en mz"><h2 class="bm jm dm bo fs na fu fv nb fx fz jk ga">Getting Started With Sentiment Analysis</h2><div class="nc l"><h3 class="bm b dm bo fs na fu fv nb fx fz cn">Notes From Natural Language Processing Specialization Course1 Week1</h3></div><div class="nd l"><p class="bm b hi bo fs na fu fv nb fx fz cn">towardsdatascience.com</p></div></div><div class="ne l"><div class="qi l ng nh ni ne nj lk mw"></div></div></div></a></div><h2 class="nu nv jl bm nw nx pl nz oa ob pm od oe lz pn og oh md po oj ok mh pp om on oo ga" id="c562">Wrap Up</h2><p class="pw-post-body-paragraph lq lr jl ls b lt op km lv lw oq kp ly lz or mb mc md os mf mg mh ot mj mk ml je ga" id="928d">You’ve now see the iterative nature of Machine Learning practically… I personally like to use evidence as much as possible when I am attempting to improve my machine learning models. I try to understand the bias-variance of the model with learning curves and then use error analysis to allot my time to the task that will provide the most significant improvement to the model if I were to improve at that task.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="7a68">Thank you for reading to the end, feel free to shoot me a message on LinkedIn:</p><div class="mt mu gt gv mv mw"><a href="https://www.linkedin.com/in/kurtispykes/" rel="noopener ugc nofollow" target="_blank"><div class="mx o fr"><div class="my o da dx en mz"><h2 class="bm jm dm bo fs na fu fv nb fx fz jk ga">Kurtis Pykes - Data Scientist - Freelance, self-employed | LinkedIn</h2><div class="nc l"><h3 class="bm b dm bo fs na fu fv nb fx fz cn">View Kurtis Pykes' profile on LinkedIn, the world's largest professional community. Kurtis has 3 jobs listed on their…</h3></div><div class="nd l"><p class="bm b hi bo fs na fu fv nb fx fz cn">www.linkedin.com</p></div></div><div class="ne l"><div class="qj l ng nh ni ne nj lk mw"></div></div></div></a></div><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="069c">If you are interested in starting your own blog, subscribe to me on youtube for all my best tips on how you may get started:</p><div class="mt mu gt gv mv mw"><a href="https://www.youtube.com/channel/UCu6zdBQhvEY5_j-ifHWljYw?view_as=subscriber" rel="noopener ugc nofollow" target="_blank"><div class="mx o fr"><div class="my o da dx en mz"><h2 class="bm jm dm bo fs na fu fv nb fx fz jk ga">Kurtis Pykes</h2><div class="nc l"><h3 class="bm b dm bo fs na fu fv nb fx fz cn">Enjoy the videos and music you love, upload original content, and share it all with friends, family, and the world on…</h3></div><div class="nd l"><p class="bm b hi bo fs na fu fv nb fx fz cn">www.youtube.com</p></div></div><div class="ne l"><div class="qk l ng nh ni ne nj lk mw"></div></div></div></a></div></div></div></section></div></div></article>