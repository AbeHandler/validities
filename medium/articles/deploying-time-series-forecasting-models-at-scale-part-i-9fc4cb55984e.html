<article class="meteredContent"><div class="l"><div class="gg gh gi gj gk gl gm ce gn ch l"></div><div class="l"><header class="pw-post-byline-header go gp gq gr gs gt gu gv gw gx l"><div class="o gy u"><div class="o"><div class="fj l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://igodfried.medium.com/?source=post_page-----9fc4cb55984e--------------------------------" rel="noopener follow"><div class="l do"><img alt="Isaac Godfried" class="l ch fl gz ha fp" height="48" loading="lazy" src="https://miro.medium.com/fit/c/96/96/0*Sx7X1u5ElAJwgTxr." width="48"/><div class="fk fl l gz ha fo aq"></div></div></a></div><div class="l"><div class="pw-author bm b dm dn ga"><div class="hb o hc"><div><div aria-hidden="false" class="ci"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://igodfried.medium.com/?source=post_page-----9fc4cb55984e--------------------------------" rel="noopener follow">Isaac Godfried</a></div></div><div class="hd he hf hg hh d"><span><a class="bm b hi bo hj hk hl hm hn ho hp bd bz hq hr hs cd cf cg ch ci cj" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5bebc59e793b&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploying-time-series-forecasting-models-at-scale-part-i-9fc4cb55984e&amp;user=Isaac+Godfried&amp;userId=5bebc59e793b&amp;source=post_page-5bebc59e793b----9fc4cb55984e---------------------follow_byline-----------" rel="noopener follow">Follow</a></span></div></div></div><div class="o ao ht"><p class="pw-published-date bm b bn bo cn"><span>Feb 11, 2021</span></p><div aria-hidden="true" class="hu ci"><span aria-hidden="true" class="l"><span class="bm b bn bo cn">·</span></span></div><div class="pw-reading-time bm b bn bo cn">6 min read</div><div aria-hidden="true" class="hu ci"><span aria-hidden="true" class="l"><span class="bm b bn bo cn">·</span></span></div><div class="hx l"><div aria-hidden="false" class="l"><button class="l dz hv bb"><div class="j i d"><div><div aria-hidden="false" class="ci"><svg fill="none" height="20" viewbox="0 0 20 20" width="20"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div><div class="h k hy hz ia"><svg class="hw" fill="none" height="20" viewbox="0 0 20 20" width="20"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg><p class="bm b bn bo cn">Member-only</p></div></button></div></div></div></div></div><div class="o ao"><div class="h k ib ic id"><div class="ie l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on twitter" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ie l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on facebook" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ie l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on linkedin" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l fr"><div><div aria-hidden="false" class="ci"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8" fill-rule="evenodd"></path></svg></span></button></div></div></div><div class="ih o ao"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9fc4cb55984e&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploying-time-series-forecasting-models-at-scale-part-i-9fc4cb55984e&amp;source=--------------------------bookmark_header-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="au de aw ax ay az ba if bc hv ij ik il"><svg aria-label="Add to list bookmark button" class="ii" fill="none" height="25" viewbox="0 0 25 25" width="25"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></button></a></span></div></div><div class="ck im"><div><div aria-hidden="false" class="ci"></div></div></div></div></div><div class="in io ip j i d"><div class="fj l"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9fc4cb55984e&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploying-time-series-forecasting-models-at-scale-part-i-9fc4cb55984e&amp;source=--------------------------bookmark_header-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="au de aw iq ay az ba ir bc hv cd o ao is it il"><svg aria-label="Add to list bookmark button" class="ii" fill="none" height="25" viewbox="0 0 25 25" width="25"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg><p class="bm b bn bo cn">Save</p></button></a></span></div><div class="iu l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on twitter" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="iu l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on facebook" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="iu l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on linkedin" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l fr"><div><div aria-hidden="false" class="ci"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></header><span class="l"></span><section><div><div class="fo as ja jb jc jd"></div><div class="je jf jg jh ji"><div class=""><h1 class="pw-post-title jj jk jl bm jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ga" id="e5d4">Deploying time series forecasting models at scale (Part I)</h1></div><div class=""><h2 class="pw-subtitle-paragraph ki jk jl bm b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz cn" id="debf">How to leverage Flow-Forecast, Docker, Terraform, Airflow, Kubernetes and ONNX to easily scale your deep time series models to production workloads.</h2></div><figure class="lb lc ld le gx lf gl gm paragraph-image"><div class="lg lh do li ce lj" role="button" tabindex="0"><div class="gl gm la"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*hcjJxNAY_BSrfBide5vyHA.png 640w, https://miro.medium.com/max/720/1*hcjJxNAY_BSrfBide5vyHA.png 720w, https://miro.medium.com/max/750/1*hcjJxNAY_BSrfBide5vyHA.png 750w, https://miro.medium.com/max/786/1*hcjJxNAY_BSrfBide5vyHA.png 786w, https://miro.medium.com/max/828/1*hcjJxNAY_BSrfBide5vyHA.png 828w, https://miro.medium.com/max/1100/1*hcjJxNAY_BSrfBide5vyHA.png 1100w, https://miro.medium.com/max/1400/1*hcjJxNAY_BSrfBide5vyHA.png 1400w"/><img alt="" class="ce lk ll c" height="280" loading="eager" role="presentation" width="700"/></picture></div></div><figcaption class="lm bl gn gl gm ln lo bm b bn bo cn"><a class="au lp" href="https://unsplash.com/photos/XLFu0PM5Qsg" rel="noopener ugc nofollow" target="_blank">Photo Unsplash</a></figcaption></figure><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="26f4">Deploying machine learning models remains a sticking point for many companies and time series forecasting models are no exception. According to <a class="au lp" href="/why-90-percent-of-all-machine-learning-models-never-make-it-into-production-ce7e250d5a4a" rel="noopener" target="_blank">VentureBeat around 90% of models never make it into production</a>. While there might be many reasons for this (e.g. models were exploratory in nature and the end goal was never production, etc) suffice to say that many promising models are shelved at this stage. This is especially true of deep learning models that often have many moving parts.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="b2bd">In this article we will discuss general techniques for taking time series forecasting models to production. We will then more specifically dive into how to get PyTorch models trained using <a class="au lp" href="https://github.com/AIStream-Peelout/flow-forecast" rel="noopener ugc nofollow" target="_blank">Flow Forecast</a> ready for deployment. In Part II of this article series we will actually describe deploy example models with FastAPI, Docker, Terraform and Kubernetes. Finally, in Part III we will monitor them and show how to update them periodically as well as scale to increased workloads. Another series will deal with distributed training of deep learning models.</p><h2 class="mm mn jl bm mo mp mq mr ms mt mu mv mw lz mx my mz md na nb nc mh nd ne nf ng ga" id="650c">Considerations</h2><p class="pw-post-body-paragraph lq lr jl ls b lt nh km lv lw ni kp ly lz nj mb mc md nk mf mg mh nl mj mk ml je ga" id="8631"><strong class="ls jm">Prior to training</strong></p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="9fcd">As I mentioned in my <a class="au lp" href="/training-time-series-forecasting-models-in-pytorch-81ef9a66bd3a" rel="noopener" target="_blank">previous article</a> before you select a model to train you should weigh your end-goals. Is interpretability important? What inference speed do I need? Do I want a confidence intervals? Or is just a single forecasted value good? These considerations and analysis should inform which model you choose to train initially.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="22e8">Secondly, in this pre-training planning phase you should also consider how the application will interact with existing software infrastructure and what type of temporal data it will ingest. If for instance, the model needs to make real-time forecasts on a Kafka data stream then how you get it ready for deployment will differ tremendously from if the model just needs to ingest a static CSV file from a GCP bucket. This can also cause things like scalers to break as previously they might have scaled on an entire CSV file with all the most recent data appended whereas now to facilitate fast inference we won’t be able to recompute either the scaler or the CSV file.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="250f">Finally, you should consider how long it will take to re-train or continue to train the model. If you are going to periodically get new data and if your models need to be re-trained from scratch each time (for instance due to catastrophic forgetting) it is going to eat up a lot of resources.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="c9d6"><strong class="ls jm">Choosing your overall forecast length</strong></p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="8f21">A big bottleneck remains forecasting long length time series data as the model can only predict values as long as its output forecast length. This means that if you have a model that only forecasts one time step at a time and want to forecast 200 time steps into the future you will need to run 200 forward passes (at least for most models) plus append operations. Whereas if you have model that forecast 10 time steps at once you would only need 20. For this reason when long forecast lengths don’t degrade performance you should use them.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="3f0b"><strong class="ls jm">Is the model with lowest test loss really the best model?</strong></p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="ce62">Oftentimes, the model with the best test loss might perform poorly in a full production setting. This is mainly due to distribution shift in the data and poor selection of evaluation metrics. For this reason you will want to evaluate your model in a rigorous fashion prior to deployment. In order to do this I recommend analyzing both the overall test loss, the test loss on the most recent data, and the interpretability graphs. You can also look at what your model does during extreme situations. Even if the forecasting problem is complex we often a have basic intuition about what should happen or the general direction the prediction should go in. For example if you have a model that forecasts river flow for river that usually only get 2 inches of precipitation per month you could try inputting 20 inches of precipitation in a single hour. Obviously the river flow prediction should then shoot up to epic heights (after whatever the normal time lag is). If it doesn’t then you know something is wrong.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="77e0"><strong class="ls jm">Double Checking Production Workflows</strong></p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="5b5f">In this phase there can often be “unexpected sources” of distribution shift. You should ideally write unit-tests to make sure the model makes the same predictions in production as it does on the test data. I can not overstate this enough CHECK YOUR INPUT DATA. Extremely small differences in pre-processing can often result in big differences in accuracy. Many times people are quick to blame a faulty model, but a lot of time improper data cleaning and changing data format is to blame. You should also communicate with your data engineering/backend teams to see if they anticipate data format changes. Finally, you can write end-to-end tests that make sure the model coupled with pre-processing and post-processing produce sensible results.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="ba0e"><strong class="ls jm">Single model or multiple models</strong></p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="95ab">Another difference that your initial model selection will make is whether you need to deploy single or multiple models. For instance, you might train a separate DNN on each store you want to forecast or you might train one DNN on all stores. In the latter your model will need to have access to the store id (and other information) at inference time as well as the temporal information. In this case you will also need to keep track of model outputs (especially if you are batching multiple store locations together at once). In the former you will need to deploy more models but since they are separate they are at least more parallelizible in terms of inference.</p><h2 class="mm mn jl bm mo mp mq mr ms mt mu mv mw lz mx my mz md na nb nc mh nd ne nf ng ga" id="8fd1">Getting models ready for deployment with Flow Forecast</h2><p class="pw-post-body-paragraph lq lr jl ls b lt nh km lv lw ni kp ly lz nj mb mc md nk mf mg mh nl mj mk ml je ga" id="a7af">Flow Forecast has a number of built tools to help you with the model deployment process. We have an easy to use automated inference API that provides the full functionality of evaluator class. Unless you need to deploy your model in a different language or need very low inference speed then we recommend simply wrapping this class into your Python (web) application or use one of our pre-built Docker containers that creates an automated inference API. However, even if you decide you need to export it you still want to start with the inference API as it makes these next two steps easy.</p><ol class=""><li class="nm nn jl ls b lt lu lw lx lz no md np mh nq ml nr ns nt nu ga" id="2d70"><strong class="ls jm">Robustness testing</strong></li></ol><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="ace3">Using the Flow-Forecast Inference API you can easily plot how the model performs on different time periods. Our standard suite of interpretability metrics are already automatically logged to Weights and Biases. To see a compl<a class="au lp" href="https://gist.github.com/isaacmg/b95a4a9f0f56a7607fa2e46670371268" rel="noopener ugc nofollow" target="_blank">ete example of how this works you can look at this notebook.</a></p><figure class="lb lc ld le gx lf"><div class="m fs l do"><div class="nv nw l"></div></div><figcaption class="lm bl gn gl gm ln lo bm b bn bo cn">Example of instantiating a model using FF inference mode.</figcaption></figure><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="7258"><strong class="ls jm">2. Inference speed testing and speed ups</strong></p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="711d">Another feature we have in Flow Forecast is automatic timing of how long it takes your model to forecast different forecast lengths on various devices and the difference between vanilla models, TorchScript, and ONNX. Additionally we are working on several new enhancements to speed up inference such as generating the confidence interval in large batches and faster logging of plots.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="c248"><strong class="ls jm">3. Exporting to TorchScript and ONNX</strong></p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="6103">As of Flow Forecast 0.95 we have support for TorchScript and we plan on having support for ONNX by 0.96. However there are several drawbacks to using these methods including the loss of confidence intervals. To put the model into TorchScript/ONNX it requires calling <code class="fp nx ny nz oa b">model.eval()</code> which means all predictions will be the same hence no confidence interval. That said if you want to convert the model to TorchScript (assuming you had already followed the steps in the gist above) you would do essentially this:</p><pre class="lb lc ld le gx ob bs oc od dz oa"><span class="ga mm mn jl oa b dm oe of l og oh" id="3aff">from flood_forecast.deployment.inference import convert_to_torch_script </span><span class="ga mm mn jl oa b dm oi of l og oh" id="235d">convert_to_torch_script(d, "torch_script_save_path.pt")</span></pre><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="0738">See <a class="au lp" href="https://github.com/AIStream-Peelout/flow-forecast/blob/a750601743695d8cc7bef00dd964f32a070b49c1/flood_forecast/deployment/inference.py#L118" rel="noopener ugc nofollow" target="_blank">this link for more</a> information.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="8bb5"><strong class="ls jm">4. Current data ingestion and future versions</strong></p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="bcc6">At the moment InferenceMode only supports loading inference data from a CSV. However we are hoping to change that in the near future and allow data loading from many different data sources. Specifically we are prioritizing loading data directly from SQL tables, Parquet files, and HDFS. Later on in our roadmap we plan to allow streaming data sources like Kafka subscriptions, Redis, or Pub/Sub.</p><p class="pw-post-body-paragraph lq lr jl ls b lt lu km lv lw lx kp ly lz ma mb mc md me mf mg mh mi mj mk ml je ga" id="9df5">In this article we covered some of the preparatory steps to deploying your model. Once you have done these things you can start to focus on the actual deployment phase. In the second article we will examine how to perform the actual deployment by using the Flow Forecast Inference Docker container, our Terraform templates, and Google Cloud Platform. This article will be more hand and contain more code samples. Feel free to leave questions if you have any.</p></div></div></section></div></div></article>