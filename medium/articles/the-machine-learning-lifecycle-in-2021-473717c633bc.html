<article><div class="l"><div class="gg gh gi gj gk gl gm ce gn ch l"></div><div class="l"><header class="pw-post-byline-header go gp gq gr gs gt gu gv gw gx l"><div class="o gy u"><div class="o"><div class="fj l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/@eric.hofesmann?source=post_page-----473717c633bc--------------------------------" rel="noopener follow"><div class="l do"><img alt="Eric Hofesmann" class="l ch fl gz ha fp" height="48" loading="lazy" src="https://miro.medium.com/fit/c/96/96/0*S8RZG2aFx5n-2tTg" width="48"/><div class="fk fl l gz ha fo aq"></div></div></a></div><div class="l"><div class="pw-author bm b dm dn ga"><div class="hb o hc"><div><div aria-hidden="false" class="ci"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/@eric.hofesmann?source=post_page-----473717c633bc--------------------------------" rel="noopener follow">Eric Hofesmann</a></div></div><div class="hd he hf hg hh d"><span><a class="bm b hi bo hj hk hl hm hn ho hp bd bz hq hr hs cd cf cg ch ci cj" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9d47b12d8682&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-machine-learning-lifecycle-in-2021-473717c633bc&amp;user=Eric+Hofesmann&amp;userId=9d47b12d8682&amp;source=post_page-9d47b12d8682----473717c633bc---------------------follow_byline-----------" rel="noopener follow">Follow</a></span></div></div></div><div class="o ao ht"><p class="pw-published-date bm b bn bo cn"><span>Jan 21, 2021</span></p><div aria-hidden="true" class="hu ci"><span aria-hidden="true" class="l"><span class="bm b bn bo cn">Â·</span></span></div><div class="pw-reading-time bm b bn bo cn">11 min read</div></div></div></div><div class="o ao"><div class="h k hv hw hx"><div class="hy l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on twitter" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hy l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on facebook" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hy l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on linkedin" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l fr"><div><div aria-hidden="false" class="ci"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8" fill-rule="evenodd"></path></svg></span></button></div></div></div><div class="ib o ao"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F473717c633bc&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-machine-learning-lifecycle-in-2021-473717c633bc&amp;source=--------------------------bookmark_header-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="au de aw ax ay az ba hz bc id ie if ig"><svg aria-label="Add to list bookmark button" class="ic" fill="none" height="25" viewbox="0 0 25 25" width="25"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></button></a></span></div></div><div class="ck ih"><div><div aria-hidden="false" class="ci"></div></div></div></div></div><div class="ii ij ik j i d"><div class="fj l"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F473717c633bc&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-machine-learning-lifecycle-in-2021-473717c633bc&amp;source=--------------------------bookmark_header-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="au de aw il ay az ba im bc id cd o ao in io ig"><svg aria-label="Add to list bookmark button" class="ic" fill="none" height="25" viewbox="0 0 25 25" width="25"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg><p class="bm b bn bo cn">Save</p></button></a></span></div><div class="ip l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on twitter" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ip l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on facebook" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ip l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on linkedin" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l fr"><div><div aria-hidden="false" class="ci"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></header><span class="l"></span><section><div><div class="fo as iv iw ix iy"></div><div class="iz ja jb jc jd"><div class=""><h1 class="pw-post-title je jf jg bm jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ga" id="8823">The Machine Learning Lifecycle in 2021</h1></div><div class=""><h2 class="pw-subtitle-paragraph kd jf jg bm b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku cn" id="7cd0">How do you actually complete a machine learning project and what are some tools that can help each step of the way?</h2></div><figure class="kw kx ky kz gx la gl gm paragraph-image"><div class="lb lc do ld ce le" role="button" tabindex="0"><div class="gl gm kv"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/0*z0CL8lFNxQQUGutC 640w, https://miro.medium.com/max/720/0*z0CL8lFNxQQUGutC 720w, https://miro.medium.com/max/750/0*z0CL8lFNxQQUGutC 750w, https://miro.medium.com/max/786/0*z0CL8lFNxQQUGutC 786w, https://miro.medium.com/max/828/0*z0CL8lFNxQQUGutC 828w, https://miro.medium.com/max/1100/0*z0CL8lFNxQQUGutC 1100w, https://miro.medium.com/max/1400/0*z0CL8lFNxQQUGutC 1400w"/><img alt="" class="ce lf lg c" height="364" loading="eager" role="presentation" width="700"/></picture></div></div><figcaption class="lh bl gn gl gm li lj bm b bn bo cn">Photo by <a class="au lk" href="https://unsplash.com/@tolga__?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Tolga Ulkan</a> on <a class="au lk" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="6447">Everyone <a class="au lk" href="https://www.geekwire.com/2019/diy-ai-one-moms-quest-use-machine-learning-help-others-detect-rare-fetal-condition/" rel="noopener ugc nofollow" target="_blank">and their mother</a> is getting into machine learning (ML) in this day and age. It seems that every company that is collecting data is trying to figure out some way to use AI and ML to analyze their business and provide automated solutions.</p><blockquote class="mh"><p class="mi mj jg bm mk ml mm mn mo mp mq mg cn" id="586c">The machine learning market cap is expected to reach $117 billion by 2027 â <a class="au lk" href="https://www.globenewswire.com/news-release/2020/07/17/2063938/0/en/Machine-Learning-Market-to-Reach-USD-117-19-Billion-by-2027-Increasing-Popularity-of-Self-Driving-Cars-to-Propel-Demand-from-Automotive-Industry-says-Fortune-Business-Insights.html" rel="noopener ugc nofollow" target="_blank">Fortune Business Insights</a></p></blockquote><p class="pw-post-body-paragraph ll lm jg ln b lo mr kh lq lr ms kk lt lu mt lw lx ly mu ma mb mc mv me mf mg iz ga" id="13bb">This influx of popularity in ML is leading to a lot of newcomers without a formal background getting into the space. While itâs great that more people are getting excited and learning about this field, it needs to be clear that incorporating an ML project in a production setting is not an easy task.</p><figure class="kw kx ky kz gx la gl gm paragraph-image"><div class="lb lc do ld ce le" role="button" tabindex="0"><div class="gl gm mw"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*8PZ3hlECzYqHxNOCWNJrkw.png 640w, https://miro.medium.com/max/720/1*8PZ3hlECzYqHxNOCWNJrkw.png 720w, https://miro.medium.com/max/750/1*8PZ3hlECzYqHxNOCWNJrkw.png 750w, https://miro.medium.com/max/786/1*8PZ3hlECzYqHxNOCWNJrkw.png 786w, https://miro.medium.com/max/828/1*8PZ3hlECzYqHxNOCWNJrkw.png 828w, https://miro.medium.com/max/1100/1*8PZ3hlECzYqHxNOCWNJrkw.png 1100w, https://miro.medium.com/max/1400/1*8PZ3hlECzYqHxNOCWNJrkw.png 1400w"/><img alt="" class="ce lf lg c" height="487" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lh bl gn gl gm li lj bm b bn bo cn">Image from the <a class="au lk" href="https://info.algorithmia.com/hubfs/2019/Whitepapers/The-State-of-Enterprise-ML-2020/Algorithmia_2020_State_of_Enterprise_ML.pdf" rel="noopener ugc nofollow" target="_blank">2020 State of Enterprise ML</a> by <a class="au lk" href="https://algorithmia.com/" rel="noopener ugc nofollow" target="_blank">Algorithmia</a> based on 750 businesses</figcaption></figure><blockquote class="mh"><p class="mi mj jg bm mk ml mx my mz na nb mg cn" id="87e4">55% of businesses working on ML models have yet to get them into production â <a class="au lk" href="https://info.algorithmia.com/hubfs/2019/Whitepapers/The-State-of-Enterprise-ML-2020/Algorithmia_2020_State_of_Enterprise_ML.pdf" rel="noopener ugc nofollow" target="_blank">Algorithmia</a></p></blockquote><p class="pw-post-body-paragraph ll lm jg ln b lo mr kh lq lr ms kk lt lu mt lw lx ly mu ma mb mc mv me mf mg iz ga" id="fbc8">Many people seem to be under the assumption that an ML project is fairly straightforward if you have the data and computing resources necessary to train a model. They could not be more wrong. This assumption seems to lead to significant time and monetary costs without ever deploying a model.</p><figure class="kw kx ky kz gx la gl gm paragraph-image"><div class="lb lc do ld ce le" role="button" tabindex="0"><div class="gl gm nc"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 630px" srcset="https://miro.medium.com/max/640/1*J6cWDw0liePv729XkterGQ.png 640w, https://miro.medium.com/max/720/1*J6cWDw0liePv729XkterGQ.png 720w, https://miro.medium.com/max/750/1*J6cWDw0liePv729XkterGQ.png 750w, https://miro.medium.com/max/786/1*J6cWDw0liePv729XkterGQ.png 786w, https://miro.medium.com/max/828/1*J6cWDw0liePv729XkterGQ.png 828w, https://miro.medium.com/max/1100/1*J6cWDw0liePv729XkterGQ.png 1100w, https://miro.medium.com/max/1260/1*J6cWDw0liePv729XkterGQ.png 1260w"/><img alt="" class="ce lf lg c" height="223" loading="lazy" role="presentation" width="630"/></picture></div></div><figcaption class="lh bl gn gl gm li lj bm b bn bo cn">Naive assumption of the ML lifecycle (Image by author)</figcaption></figure><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="04a6">In this article, weâll discuss what the lifecycle of an ML project actually looks like and some tools to help tackle it.</p></div><div class="o dx nd ne ii nf" role="separator"><span class="ng fl ci nh ni nj"></span><span class="ng fl ci nh ni nj"></span><span class="ng fl ci nh ni"></span></div><div class="iz ja jb jc jd"><h1 class="nk nl jg bm nm nn no np nq nr ns nt nu km nv kn nw kp nx kq ny ks nz kt oa ob ga" id="afdd">The Machine Learning Lifecycle</h1><p class="pw-post-body-paragraph ll lm jg ln b lo oc kh lq lr od kk lt lu oe lw lx ly of ma mb mc og me mf mg iz ga" id="64e8">In reality, machine learning projects are not straightforward, they are a cycle iterating between improving the data, model, and evaluation that is never really finished. This cycle is crucial in developing an ML model because it focuses on using model results and evaluation to refine your dataset. A high-quality dataset is the most surefire way to train a high-quality model. The speed that this cycle is iterated through is what determines your costs, luckily there are tools that can help speed up the cycle without sacrificing quality.</p><figure class="kw kx ky kz gx la gl gm paragraph-image"><div class="lb lc do ld ce le" role="button" tabindex="0"><div class="gl gm oh"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*dydm-hyCE1Dn9BLy6lSEDw.png 640w, https://miro.medium.com/max/720/1*dydm-hyCE1Dn9BLy6lSEDw.png 720w, https://miro.medium.com/max/750/1*dydm-hyCE1Dn9BLy6lSEDw.png 750w, https://miro.medium.com/max/786/1*dydm-hyCE1Dn9BLy6lSEDw.png 786w, https://miro.medium.com/max/828/1*dydm-hyCE1Dn9BLy6lSEDw.png 828w, https://miro.medium.com/max/1100/1*dydm-hyCE1Dn9BLy6lSEDw.png 1100w, https://miro.medium.com/max/1400/1*dydm-hyCE1Dn9BLy6lSEDw.png 1400w"/><img alt="" class="ce lf lg c" height="715" loading="eager" role="presentation" width="700"/></picture></div></div><figcaption class="lh bl gn gl gm li lj bm b bn bo cn">A realistic example of ML lifecycle (Image by author)</figcaption></figure><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="ee49">Much like any system, even a deployed ML model requires monitoring, maintenance, and updates. You canât just deploy an ML model and forget about it, expecting it to work as well as it did on your test set in the real world for the rest of time. ML models deployed in production environments are going to need updates as you find biases in the model, add new sources of data, require additional functionality, etc. This brings you right back into the data, model, and evaluation cycle.</p><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="7417">As of 2021, deep learning has been prominent for over a decade now and helped bring ML front and center in the market. The ML industry has undergone a boom with countless products being developed to aid in the creation of ML models. Every step of the ML lifecycle has some tool that you can use to expedite the process and not end up as one of the companies with an ML project that never sees the light of day.</p><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="0777">The next sections will deep dive into each phase of the ML lifecycle and highlight popular tools.</p><h1 class="nk nl jg bm nm nn oi np nq nr oj nt nu km ok kn nw kp ol kq ny ks om kt oa ob ga" id="8f08">Phase 1: Data</h1><figure class="kw kx ky kz gx la gl gm paragraph-image"><div class="gl gm on"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 440px" srcset="https://miro.medium.com/max/640/1*g2Pk9rgrifxNSi2QSAjJCA.png 640w, https://miro.medium.com/max/720/1*g2Pk9rgrifxNSi2QSAjJCA.png 720w, https://miro.medium.com/max/750/1*g2Pk9rgrifxNSi2QSAjJCA.png 750w, https://miro.medium.com/max/786/1*g2Pk9rgrifxNSi2QSAjJCA.png 786w, https://miro.medium.com/max/828/1*g2Pk9rgrifxNSi2QSAjJCA.png 828w, https://miro.medium.com/max/1100/1*g2Pk9rgrifxNSi2QSAjJCA.png 1100w, https://miro.medium.com/max/880/1*g2Pk9rgrifxNSi2QSAjJCA.png 880w"/><img alt="" class="ce lf lg c" height="330" loading="lazy" role="presentation" width="440"/></picture></div><figcaption class="lh bl gn gl gm li lj bm b bn bo cn">Data in the ML lifecycle (Image by author)</figcaption></figure><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="fb2d">While the end goal is a high-quality model, the lifeblood of training a good model is in the amount and more importantly the quality of the data being passed into it.</p><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="902e">The primary data related steps in the ML lifecycle are:</p><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="a2db"><strong class="ln jh">Data Collection</strong> â Collect as much raw data as possible regardless of quality In the end, only a small subset of it will be annotated anyway which is where most of the cost comes from. It is useful to have a lot of data available to add as needed when problems arise with model performance.</p><ul class=""><li class="oo op jg ln b lo lp lr ls lu oq ly or mc os mg ot ou ov ow ga" id="560f"><a class="au lk" href="https://medium.com/towards-artificial-intelligence/best-datasets-for-machine-learning-data-science-computer-vision-nlp-ai-c9541058cf4f" rel="noopener">List of public datasets</a></li></ul><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="d543"><strong class="ln jh">Define your annotation schema </strong>â This is one of the most important parts of the data phase of the lifecycle, and it often gets overlooked. A poorly constructed annotation schema will result in ambiguous classes and edge cases that make it much more difficult to train a model.</p><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="d810">For example, <a class="au lk" href="https://dhoiem.web.engr.illinois.edu/publications/eccv2012_detanalysis_derek.pdf" rel="noopener ugc nofollow" target="_blank">the performance of object detection models</a> depends heavily on attributes like size, localization, orientation, and truncation. So including attributes like object size, density, and occlusion during annotation can provide critical metadata needed to create high-quality training datasets that models can learn from.</p><ul class=""><li class="oo op jg ln b lo lp lr ls lu oq ly or mc os mg ot ou ov ow ga" id="fded"><a class="au lk" href="https://matplotlib.org/" rel="noopener ugc nofollow" target="_blank">Matplotlib</a>, <a class="au lk" href="https://plotly.com/" rel="noopener ugc nofollow" target="_blank">Plotly</a> â Plot properties of your data</li><li class="oo op jg ln b lo ox lr oy lu oz ly pa mc pb mg ot ou ov ow ga" id="9cc6"><a class="au lk" href="https://www.tableau.com/" rel="noopener ugc nofollow" target="_blank">Tableu</a> â Analytics platform to better understand your data</li></ul><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="d5de"><strong class="ln jh">Data Annotation</strong>âAnnotation is a tedious process of performing the same task on and on for hours at a time, which is why annotation services are a booming business. The result is that annotators will likely make numerous mistakes. While most annotation firms guarantee a maximum error percentage (ex. 2% max error), a larger problem is a poorly defined annotation schema resulting in annotators deciding to label samples differently. This is harder to spot by the QA team of an annotation firm and is something that you need to check yourself.</p><ul class=""><li class="oo op jg ln b lo lp lr ls lu oq ly or mc os mg ot ou ov ow ga" id="531a"><a class="au lk" href="https://scale.com/" rel="noopener ugc nofollow" target="_blank">Scale</a>, <a class="au lk" href="https://app.labelbox.com/signin" rel="noopener ugc nofollow" target="_blank">Labelbox</a>, <a class="au lk" href="https://prodi.gy/" rel="noopener ugc nofollow" target="_blank">Prodigy</a> â Popular annotation services</li><li class="oo op jg ln b lo ox lr oy lu oz ly pa mc pb mg ot ou ov ow ga" id="8f5c"><a class="au lk" href="https://www.mturk.com/" rel="noopener ugc nofollow" target="_blank">Mechanical Turk</a> â Crowdsourced annotation</li><li class="oo op jg ln b lo ox lr oy lu oz ly pa mc pb mg ot ou ov ow ga" id="cda4"><a class="au lk" href="https://github.com/openvinotoolkit/cvat" rel="noopener ugc nofollow" target="_blank">CVAT</a> â DIY computer vision annotation</li><li class="oo op jg ln b lo ox lr oy lu oz ly pa mc pb mg ot ou ov ow ga" id="560a"><a class="au lk" href="https://github.com/doccano/doccano" rel="noopener ugc nofollow" target="_blank">Doccano</a> â NLP specific annotation tool</li><li class="oo op jg ln b lo ox lr oy lu oz ly pa mc pb mg ot ou ov ow ga" id="9b20"><a class="au lk" href="https://www.centaurlabs.com/" rel="noopener ugc nofollow" target="_blank">Centaur Labs</a> â Medical data labeling service</li></ul><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="ecff"><strong class="ln jh">Improve dataset and annotations</strong> â You will likely spend the majority of your time here when trying to improve model performance. If your model is learning but not performing well, the culprit is almost always a training dataset containing biases and mistakes that are <a class="au lk" href="/i-performed-error-analysis-on-open-images-and-now-i-have-trust-issues-89080e03ba09" rel="noopener" target="_blank">creating a performance ceiling for your model</a>. Improving your model generally involves things like <a class="au lk" href="https://youtu.be/hx7BXih7zx8?t=514" rel="noopener ugc nofollow" target="_blank">hard sample mining (adding new training data similar to other samples the model failed on)</a>, rebalancing your dataset based on biases your model has learned, and updating your annotations and schema to add new labels and refine existing ones.</p><ul class=""><li class="oo op jg ln b lo lp lr ls lu oq ly or mc os mg ot ou ov ow ga" id="fab4"><a class="au lk" href="https://dagshub.com/" rel="noopener ugc nofollow" target="_blank">DAGsHub</a> â Dataset versioning</li><li class="oo op jg ln b lo ox lr oy lu oz ly pa mc pb mg ot ou ov ow ga" id="47fa"><a class="au lk" href="https://voxel51.com/docs/fiftyone/" rel="noopener ugc nofollow" target="_blank">FiftyOne</a> â Visualize datasets and find mistakes</li></ul><h1 class="nk nl jg bm nm nn oi np nq nr oj nt nu km ok kn nw kp ol kq ny ks om kt oa ob ga" id="55bd">Phase 2: Model</h1><figure class="kw kx ky kz gx la gl gm paragraph-image"><div class="gl gm pc"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 423px" srcset="https://miro.medium.com/max/640/1*Pf6cdFuz1liHHzosOIv_cQ.png 640w, https://miro.medium.com/max/720/1*Pf6cdFuz1liHHzosOIv_cQ.png 720w, https://miro.medium.com/max/750/1*Pf6cdFuz1liHHzosOIv_cQ.png 750w, https://miro.medium.com/max/786/1*Pf6cdFuz1liHHzosOIv_cQ.png 786w, https://miro.medium.com/max/828/1*Pf6cdFuz1liHHzosOIv_cQ.png 828w, https://miro.medium.com/max/1100/1*Pf6cdFuz1liHHzosOIv_cQ.png 1100w, https://miro.medium.com/max/846/1*Pf6cdFuz1liHHzosOIv_cQ.png 846w"/><img alt="" class="ce lf lg c" height="267" loading="lazy" role="presentation" width="423"/></picture></div><figcaption class="lh bl gn gl gm li lj bm b bn bo cn">Models in the ML lifecycle (Image by author)</figcaption></figure><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="76f2">Even though the output of this process is a model, you will ideally spend the least amount of time in this loop.</p><figure class="kw kx ky kz gx la gl gm paragraph-image"><div class="lb lc do ld ce le" role="button" tabindex="0"><div class="gl gm pd"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/0*xCQvREm6ErR6AWk4.jpeg 640w, https://miro.medium.com/max/720/0*xCQvREm6ErR6AWk4.jpeg 720w, https://miro.medium.com/max/750/0*xCQvREm6ErR6AWk4.jpeg 750w, https://miro.medium.com/max/786/0*xCQvREm6ErR6AWk4.jpeg 786w, https://miro.medium.com/max/828/0*xCQvREm6ErR6AWk4.jpeg 828w, https://miro.medium.com/max/1100/0*xCQvREm6ErR6AWk4.jpeg 1100w, https://miro.medium.com/max/1400/0*xCQvREm6ErR6AWk4.jpeg 1400w"/><img alt="" class="ce lf lg c" height="419" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lh bl gn gl gm li lj bm b bn bo cn">In industry, more time is spent on datasets than models. Credit to Andrej Karpathy (<a class="au lk" href="https://medium.com/voice-tech-podcast/how-do-you-know-that-your-nlp-model-is-production-ready-2c6724e16de" rel="noopener">source</a>, <a class="au lk" href="https://www.youtube.com/watch?t=512&amp;v=y57wwucbXR8&amp;feature=youtu.be" rel="noopener ugc nofollow" target="_blank">original talk</a> )</figcaption></figure><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="a1d5"><strong class="ln jh">Explore existing pretrained models</strong> â The goal here is to reuse as many available resources as possible to give yourself the best head start to model production. Transfer learning is a core tenant of deep learning in this day and age. You will likely not be creating a model from scratch, but instead fine-tuning an existing model that was pretrained on a related task. For example, if you want to create a mask detection model, you will likely download a pretrained face detection model from GitHub since that is a more popular topic with more prior work.</p><ul class=""><li class="oo op jg ln b lo lp lr ls lu oq ly or mc os mg ot ou ov ow ga" id="90f9"><a class="au lk" href="https://voxel51.com/docs/fiftyone/user_guide/model_zoo/index.html" rel="noopener ugc nofollow" target="_blank">FiftyOne model zoo</a> â Download and run models in one line of code</li><li class="oo op jg ln b lo ox lr oy lu oz ly pa mc pb mg ot ou ov ow ga" id="4e28"><a class="au lk" href="https://www.tensorflow.org/hub" rel="noopener ugc nofollow" target="_blank">TensorFlow Hub</a> â Repository of trained ML models</li><li class="oo op jg ln b lo ox lr oy lu oz ly pa mc pb mg ot ou ov ow ga" id="6d62"><a class="au lk" href="https://modelzoo.co/" rel="noopener ugc nofollow" target="_blank">modelzoo.co</a> â Pretrained deep learning models for various tasks and libraries</li></ul><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="1ae1"><strong class="ln jh">Construct training loop</strong> â Your data will likely differ in some way from what was used to pretrain the model. For image datasets, things like input resolution and object sizes need to be taken into account when setting up the training pipeline for your model. You will also need to modify the output structure of the model to match the classes and structure of your labels. <a class="au lk" href="https://github.com/PyTorchLightning/pytorch-lightning" rel="noopener ugc nofollow" target="_blank">PyTorch lightning</a> provides an easy way to scale up model training with limited code.</p><ul class=""><li class="oo op jg ln b lo lp lr ls lu oq ly or mc os mg ot ou ov ow ga" id="ff87"><a class="au lk" href="https://scikit-learn.org/" rel="noopener ugc nofollow" target="_blank">Scikit Learn</a> â Build and visualize classic ML systems</li><li class="oo op jg ln b lo ox lr oy lu oz ly pa mc pb mg ot ou ov ow ga" id="e562"><a class="au lk" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank">PyTorch</a>, <a class="au lk" href="https://github.com/PyTorchLightning/pytorch-lightning" rel="noopener ugc nofollow" target="_blank">PyTorch Lightning</a>, <a class="au lk" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank">TensorFlow</a>, <a class="au lk" href="https://github.com/google/trax" rel="noopener ugc nofollow" target="_blank">TRAX</a> â Popular deep learning Python libraries</li><li class="oo op jg ln b lo ox lr oy lu oz ly pa mc pb mg ot ou ov ow ga" id="83f0"><a class="au lk" href="https://aws.amazon.com/sagemaker/" rel="noopener ugc nofollow" target="_blank">Sagemaker</a> â Build and train ML systems in the Sagemaker IDE</li></ul><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="ba96"><strong class="ln jh">Experiment Tracking</strong> â This entire cycle will likely require multiple iterations. You will end up training a lot of different models so being meticulous in your tracking of different versions of a model and the hyperparameters and data it was trained on will help a great deal to keep things organized.</p><ul class=""><li class="oo op jg ln b lo lp lr ls lu oq ly or mc os mg ot ou ov ow ga" id="b9a8"><a class="au lk" href="https://www.tensorflow.org/tensorboard" rel="noopener ugc nofollow" target="_blank">Tensorboard</a>, <a class="au lk" href="https://wandb.ai/" rel="noopener ugc nofollow" target="_blank">Weights &amp; Biases</a>, <a class="au lk" href="https://mlflow.org/" rel="noopener ugc nofollow" target="_blank">MLFlow</a> â Visualize and track model hyperparameters</li></ul><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="bdcd"><em class="pe">Side Note</em>: Even if you think your task is completely unique, here are some pre-training techniques to consider. I would recommend looking into ways to pretrain your model in unsupervised or semi-supervised ways, still only using a small subset of your total raw data for finetuning. Depending on your task, you could also look into synthetic data to pretrain your model. The goal is just to get a model that has learned a good representation of your data so that your fine-tuning dataset only needs to be used to train a few layers worth of model parameters.</p><h1 class="nk nl jg bm nm nn oi np nq nr oj nt nu km ok kn nw kp ol kq ny ks om kt oa ob ga" id="53aa">Phase 3: Evaluation</h1><figure class="kw kx ky kz gx la gl gm paragraph-image"><div class="gl gm pf"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 331px" srcset="https://miro.medium.com/max/640/1*VL-_JFSpJ29SKIvbUf4bIA.png 640w, https://miro.medium.com/max/720/1*VL-_JFSpJ29SKIvbUf4bIA.png 720w, https://miro.medium.com/max/750/1*VL-_JFSpJ29SKIvbUf4bIA.png 750w, https://miro.medium.com/max/786/1*VL-_JFSpJ29SKIvbUf4bIA.png 786w, https://miro.medium.com/max/828/1*VL-_JFSpJ29SKIvbUf4bIA.png 828w, https://miro.medium.com/max/1100/1*VL-_JFSpJ29SKIvbUf4bIA.png 1100w, https://miro.medium.com/max/662/1*VL-_JFSpJ29SKIvbUf4bIA.png 662w"/><img alt="" class="ce lf lg c" height="416" loading="lazy" role="presentation" width="331"/></picture></div><figcaption class="lh bl gn gl gm li lj bm b bn bo cn">Evaluation in the ML lifecycle (Image by author)</figcaption></figure><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="d384">Once you managed to get a model that has learned your training data, itâs time to dig in and see how well it can perform on new data.</p><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="3329">The key steps for evaluating an ML model:</p><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="dfff"><a class="au lk" href="https://voxel51.com/docs/fiftyone/index.html" rel="noopener ugc nofollow" target="_blank"><strong class="ln jh">Visualize model outputs</strong></a><strong class="ln jh"> </strong>â As soon as you have a trained model, you need to immediately run it on a few samples and look at the output. This is the best way to find if there are any bugs in your training/evaluation pipeline before running evaluation on your entire test set. It will also show if there are any glaring errors, like if two of your classes have been mislabeled.</p><ul class=""><li class="oo op jg ln b lo lp lr ls lu oq ly or mc os mg ot ou ov ow ga" id="c517"><a class="au lk" href="https://opencv.org/" rel="noopener ugc nofollow" target="_blank">OpenCV</a>, <a class="au lk" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank">Numpy</a>, <a class="au lk" href="https://matplotlib.org/" rel="noopener ugc nofollow" target="_blank">Matplotlib</a> â Write custom visualization scripts</li><li class="oo op jg ln b lo ox lr oy lu oz ly pa mc pb mg ot ou ov ow ga" id="5d4d"><a class="au lk" href="https://voxel51.com/docs/fiftyone/" rel="noopener ugc nofollow" target="_blank">FiftyOne</a> â Visualize outputs of computer vision tasks on images and videos</li></ul><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="1afb"><strong class="ln jh">Choose the right metric</strong> â Coming up with one or a few metrics can help in comparing the overall performance of models. In order to make sure you pick the best models for your task, you should develop metrics in line with your end goal. You should also update metrics as you find other important qualities you want to track. For example, if you want to start tracking how well your object detection model performs on small objects, use <a class="au lk" href="https://medium.com/datadriveninvestor/small-objects-detection-problem-c5b430996162" rel="noopener">mAP on objects with a bounding box &lt; 0.05</a> as one of your metrics.</p><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="7d40">While these gross dataset metrics can be useful in comparing the performance of multiple models, they rarely help in understanding how to improve the performance of a model.</p><ul class=""><li class="oo op jg ln b lo lp lr ls lu oq ly or mc os mg ot ou ov ow ga" id="c3a1"><a class="au lk" href="https://scikit-learn.org/" rel="noopener ugc nofollow" target="_blank">Scikit Learn</a> â Provides common metrics</li><li class="oo op jg ln b lo ox lr oy lu oz ly pa mc pb mg ot ou ov ow ga" id="c203"><a class="au lk" href="https://www.python.org/" rel="noopener ugc nofollow" target="_blank">Python</a>, <a class="au lk" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank">Numpy</a> â Develop custom metrics</li></ul><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="1975"><strong class="ln jh">Look at failure cases</strong> âEverything your model does is based on the data that it was trained on. So assuming that it is able to learn something, if it is performing more poorly than you would expect, you need to take a look at the data. It can be useful to look at cases where your model is doing well, but it is vital to look at false positives and false negatives, where your model predicted something incorrectly. After looking through enough of these samples, you will start to see patterns of failure in your model.</p><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="379e">For example, the image below shows a sample from the Open Images dataset, one false positive is shown as the back wheel. This false positive turns out to have been a missing annotation. Verifying all wheel annotations in the dataset and fixing other similar mistakes can help improve your modelâs performance on wheels.</p><figure class="kw kx ky kz gx la gl gm paragraph-image"><div class="lb lc do ld ce le" role="button" tabindex="0"><div class="gl gm pg"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/0*yDX_3AK6AHjHlW_n 640w, https://miro.medium.com/max/720/0*yDX_3AK6AHjHlW_n 720w, https://miro.medium.com/max/750/0*yDX_3AK6AHjHlW_n 750w, https://miro.medium.com/max/786/0*yDX_3AK6AHjHlW_n 786w, https://miro.medium.com/max/828/0*yDX_3AK6AHjHlW_n 828w, https://miro.medium.com/max/1100/0*yDX_3AK6AHjHlW_n 1100w, https://miro.medium.com/max/1400/0*yDX_3AK6AHjHlW_n 1400w"/><img alt="" class="ce lf lg c" height="506" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lh bl gn gl gm li lj bm b bn bo cn">Image credit to Tyler Ganter (<a class="au lk" href="/i-performed-error-analysis-on-open-images-and-now-i-have-trust-issues-89080e03ba09" rel="noopener" target="_blank">source</a>)</figcaption></figure><ul class=""><li class="oo op jg ln b lo lp lr ls lu oq ly or mc os mg ot ou ov ow ga" id="2fb3"><a class="au lk" href="https://voxel51.com/docs/fiftyone/" rel="noopener ugc nofollow" target="_blank">FiftyOne</a>, <a class="au lk" href="https://aquarium.gitbook.io/aquarium/" rel="noopener ugc nofollow" target="_blank">Aquarium</a>, <a class="au lk" href="https://scale.com/nucleus" rel="noopener ugc nofollow" target="_blank">Scale Nucleus</a> â Dataset debugging to find mistakes</li></ul><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="7989"><strong class="ln jh">Formulate solutions</strong> â Identifying failure cases is the first step in figuring out ways to fix improve your model performance. In most cases, it goes back to adding training data similar to where your model failed but it can also include things like changing pre- or post-processing steps in your pipeline or fixing annotations. No matter what the solution is, you can only fix the problems with your model by understanding where it fails.</p><h1 class="nk nl jg bm nm nn oi np nq nr oj nt nu km ok kn nw kp ol kq ny ks om kt oa ob ga" id="88f6">Phase 4: Production</h1><figure class="kw kx ky kz gx la gl gm paragraph-image"><div class="lb lc do ld ce le" role="button" tabindex="0"><div class="gl gm ph"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*A9ThINGq5fkMC3o7GEZgLw.png 640w, https://miro.medium.com/max/720/1*A9ThINGq5fkMC3o7GEZgLw.png 720w, https://miro.medium.com/max/750/1*A9ThINGq5fkMC3o7GEZgLw.png 750w, https://miro.medium.com/max/786/1*A9ThINGq5fkMC3o7GEZgLw.png 786w, https://miro.medium.com/max/828/1*A9ThINGq5fkMC3o7GEZgLw.png 828w, https://miro.medium.com/max/1100/1*A9ThINGq5fkMC3o7GEZgLw.png 1100w, https://miro.medium.com/max/1400/1*A9ThINGq5fkMC3o7GEZgLw.png 1400w"/><img alt="" class="ce lf lg c" height="590" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lh bl gn gl gm li lj bm b bn bo cn">Deploying a model (Image by author)</figcaption></figure><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="aebd">Finally! Youâve got a model that performs well on your evaluation metrics with no major errors on various edge cases.</p><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="e6b2">Now youâll need to:</p><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="09d4"><strong class="ln jh">Monitor model</strong> â Test your deployment to ensure that your model is still performing as expected on test data with respect to your evaluation metrics and things like inference speed.</p><ul class=""><li class="oo op jg ln b lo lp lr ls lu oq ly or mc os mg ot ou ov ow ga" id="56e2"><a class="au lk" href="https://www.pachyderm.com/" rel="noopener ugc nofollow" target="_blank">Pachyderm</a>, <a class="au lk" href="https://algorithmia.com/" rel="noopener ugc nofollow" target="_blank">Algorithmia</a>, <a class="au lk" href="https://www.datarobot.com/" rel="noopener ugc nofollow" target="_blank">Datarobot</a>, <a class="au lk" href="https://www.kubeflow.org/" rel="noopener ugc nofollow" target="_blank">Kubeflow</a>, <a class="au lk" href="https://mlflow.org/" rel="noopener ugc nofollow" target="_blank">MLFlow</a> â Deploy and monitor models and pipelines</li><li class="oo op jg ln b lo ox lr oy lu oz ly pa mc pb mg ot ou ov ow ga" id="503d"><a class="au lk" href="https://aws.amazon.com/machine-learning/" rel="noopener ugc nofollow" target="_blank">Amazon Web Services</a>, <a class="au lk" href="https://cloud.google.com/automl" rel="noopener ugc nofollow" target="_blank">Google AutoML</a>, <a class="au lk" href="https://azure.microsoft.com/en-us/" rel="noopener ugc nofollow" target="_blank">Microsoft Azure</a> â Cloud-based solutions for ML models</li></ul><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="5e56"><strong class="ln jh">Evaluate new data</strong> â Using a model in production means you will frequently pass brand new data through the model that it has never been tested on. Itâs important to perform evaluation and dig into specific samples to see how your model performs on any new data it encounters.</p><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="09a5"><strong class="ln jh">Continue understanding model</strong> â Some errors and biases in your model can be deep-seated and take a long time to uncover. You need to continuously test and probe your model for various edge cases and trends that could cause problems if they were to be discovered by clients instead.</p><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="4905"><strong class="ln jh">Expand capabilities</strong> â Even if everything is working perfectly, itâs possible that the model isnât increasing profits as much as you hoped. From adding new classes, developing new data streams, and making the model more efficient there are countless ways to expand the capabilities of your current model to make it even better. Any time you want to improve your system, you will need to restart the ML lifecycle to update your data, model, and evaluate it all to make sure your new features work as expected.</p><h1 class="nk nl jg bm nm nn oi np nq nr oj nt nu km ok kn nw kp ol kq ny ks om kt oa ob ga" id="cb75">FiftyOne</h1><p class="pw-post-body-paragraph ll lm jg ln b lo oc kh lq lr od kk lt lu oe lw lx ly of ma mb mc og me mf mg iz ga" id="f8c8">The above is pretty general and unbiased, but I want to tell you a little bit more about the tool Iâve been working on.</p><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="35cd">Lots of tools exist for various portions of the ML lifecycle. However, there is a pretty glaring lack of tools that help some of the key points Iâve stressed in this post. Things like visualizing complex data (like image or video) and labels or writing queries to find specific cases where your model performs poorly are generally done through manual scripting.</p><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="516f">I have been working at <a class="au lk" href="https://voxel51.com/" rel="noopener ugc nofollow" target="_blank">Voxel51</a> developing <a class="au lk" href="https://voxel51.com/docs/fiftyone/" rel="noopener ugc nofollow" target="_blank">FiftyOne</a>, an open-source data visualization tool designed to help debug datasets and models and fill this void. FiftyOne lets you visualize your image and video datasets and model predictions in a GUI either locally or remotely. It also provides powerful capabilities to evaluate models and write advanced queries for any aspects of your dataset or model output.</p><p class="pw-post-body-paragraph ll lm jg ln b lo lp kh lq lr ls kk lt lu lv lw lx ly lz ma mb mc md me mf mg iz ga" id="5e36">FiftyOne can run in notebooks so try it out in your browser with this <a class="au lk" href="https://colab.research.google.com/github/voxel51/fiftyone-examples/blob/master/examples/quickstart.ipynb" rel="noopener ugc nofollow" target="_blank">Colab Notebook</a>. Alternatively, you can easily install it with pip.</p><pre class="kw kx ky kz gx pi bs pj pk dz pl"><span class="ga pm nl jg pl b dm pn po l pp pq" id="78b3">pip install fiftyone</span></pre><figure class="kw kx ky kz gx la gl gm paragraph-image"><div class="lb lc do ld ce le" role="button" tabindex="0"><div class="gl gm pr"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/0*x6V2GZsHpzC_dTjC.png 640w, https://miro.medium.com/max/720/0*x6V2GZsHpzC_dTjC.png 720w, https://miro.medium.com/max/750/0*x6V2GZsHpzC_dTjC.png 750w, https://miro.medium.com/max/786/0*x6V2GZsHpzC_dTjC.png 786w, https://miro.medium.com/max/828/0*x6V2GZsHpzC_dTjC.png 828w, https://miro.medium.com/max/1100/0*x6V2GZsHpzC_dTjC.png 1100w, https://miro.medium.com/max/1400/0*x6V2GZsHpzC_dTjC.png 1400w"/><img alt="" class="ce lf lg c" height="481" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lh bl gn gl gm li lj bm b bn bo cn">Sample from object detection model and dataset in <a class="au lk" href="https://voxel51.com/docs/fiftyone/index.html" rel="noopener ugc nofollow" target="_blank">FiftyOne</a> (Image by author)</figcaption></figure><h1 class="nk nl jg bm nm nn oi np nq nr oj nt nu km ok kn nw kp ol kq ny ks om kt oa ob ga" id="0d32"><strong class="ba">Summary</strong></h1><p class="pw-post-body-paragraph ll lm jg ln b lo oc kh lq lr od kk lt lu oe lw lx ly of ma mb mc og me mf mg iz ga" id="c757">Only a fraction of all companies that try to incorporate machine learning (ML) into their business manage to actually deploy a model to production. The lifecycle of an ML model is not straight forward but requires continuous iterations between data and annotation improvements, model and training pipeline construction, and sample-level evaluation. If you know what youâre in for, this cycle can eventually lead to a production-ready model, but it will also need to be maintained and updated over time. Luckily, there are countless tools developed to aid in every step of this process.</p></div></div></section></div></div></article>