<article class="meteredContent"><div class="l"><div class="gg gh gi gj gk gl gm ce gn ch l"></div><div class="l"><header class="pw-post-byline-header go gp gq gr gs gt gu gv gw gx l"><div class="o gy u"><div class="o"><div class="fj l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/@shiva.v?source=post_page-----fbc3affc5e7a--------------------------------" rel="noopener follow"><div class="l do"><img alt="Shiva Vemireddy" class="l ch fl gz ha fp" height="48" loading="lazy" src="https://miro.medium.com/fit/c/96/96/2*viX_vwXUxnn5GBNNYsuAvg.png" width="48"/><div class="fk fl l gz ha fo aq"></div></div></a></div><div class="l"><div class="pw-author bm b dm dn ga"><div class="hb o hc"><div><div aria-hidden="false" class="ci"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/@shiva.v?source=post_page-----fbc3affc5e7a--------------------------------" rel="noopener follow">Shiva Vemireddy</a></div></div><div class="hd he hf hg hh d"><span><a class="bm b hi bo hj hk hl hm hn ho hp bd bz hq hr hs cd cf cg ch ci cj" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1035ce335293&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Funpacking-the-complexity-of-machine-learning-deployments-fbc3affc5e7a&amp;user=Shiva+Vemireddy&amp;userId=1035ce335293&amp;source=post_page-1035ce335293----fbc3affc5e7a---------------------follow_byline-----------" rel="noopener follow">Follow</a></span></div></div></div><div class="o ao ht"><p class="pw-published-date bm b bn bo cn"><span>Nov 19, 2019</span></p><div aria-hidden="true" class="hu ci"><span aria-hidden="true" class="l"><span class="bm b bn bo cn">·</span></span></div><div class="pw-reading-time bm b bn bo cn">10 min read</div><div aria-hidden="true" class="hu ci"><span aria-hidden="true" class="l"><span class="bm b bn bo cn">·</span></span></div><div class="hx l"><div aria-hidden="false" class="l"><button class="l dz hv bb"><div class="j i d"><div><div aria-hidden="false" class="ci"><svg fill="none" height="20" viewbox="0 0 20 20" width="20"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div><div class="h k hy hz ia"><svg class="hw" fill="none" height="20" viewbox="0 0 20 20" width="20"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg><p class="bm b bn bo cn">Member-only</p></div></button></div></div></div></div></div><div class="o ao"><div class="h k ib ic id"><div class="ie l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on twitter" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ie l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on facebook" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ie l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on linkedin" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l fr"><div><div aria-hidden="false" class="ci"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8" fill-rule="evenodd"></path></svg></span></button></div></div></div><div class="ih o ao"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffbc3affc5e7a&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Funpacking-the-complexity-of-machine-learning-deployments-fbc3affc5e7a&amp;source=--------------------------bookmark_header-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="au de aw ax ay az ba if bc hv ij ik il"><svg aria-label="Add to list bookmark button" class="ii" fill="none" height="25" viewbox="0 0 25 25" width="25"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></button></a></span></div></div><div class="ck im"><div><div aria-hidden="false" class="ci"></div></div></div></div></div><div class="in io ip j i d"><div class="fj l"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffbc3affc5e7a&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Funpacking-the-complexity-of-machine-learning-deployments-fbc3affc5e7a&amp;source=--------------------------bookmark_header-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="au de aw iq ay az ba ir bc hv cd o ao is it il"><svg aria-label="Add to list bookmark button" class="ii" fill="none" height="25" viewbox="0 0 25 25" width="25"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg><p class="bm b bn bo cn">Save</p></button></a></span></div><div class="iu l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on twitter" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="iu l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on facebook" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="iu l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on linkedin" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l fr"><div><div aria-hidden="false" class="ci"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci if dw ig"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></header><span class="l"></span><section><div><div class="fo as ja jb jc jd"></div><div class="je jf jg jh ji"><figure class="jk jl gt gv jm jn gl gm paragraph-image"><div class="jo jp do jq ce jr" role="button" tabindex="0"><div class="gl gm jj"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*-lP27bmh2vA7s0nB7GFjMQ.jpeg 640w, https://miro.medium.com/max/720/1*-lP27bmh2vA7s0nB7GFjMQ.jpeg 720w, https://miro.medium.com/max/750/1*-lP27bmh2vA7s0nB7GFjMQ.jpeg 750w, https://miro.medium.com/max/786/1*-lP27bmh2vA7s0nB7GFjMQ.jpeg 786w, https://miro.medium.com/max/828/1*-lP27bmh2vA7s0nB7GFjMQ.jpeg 828w, https://miro.medium.com/max/1100/1*-lP27bmh2vA7s0nB7GFjMQ.jpeg 1100w, https://miro.medium.com/max/1400/1*-lP27bmh2vA7s0nB7GFjMQ.jpeg 1400w"/><img alt="" class="ce js jt c" height="394" loading="eager" role="presentation" width="700"/></picture></div></div></figure><div class=""><h1 class="pw-post-title ju jv jw bm jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks ga" id="c420">Unpacking the Complexity of Machine Learning Deployments</h1></div><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="602d">Deploying and maintaining Machine Learning models at scale is one of the most pressing challenges faced by organizations today. Machine Learning workflow which includes Training, Building and Deploying machine learning models can be a long process with many roadblocks along the way. Many data science projects don’t make it to production because of challenges that slow down or halt the entire process. To overcome the challenges of model deployment, we need to identify the problems and learn what causes them. Some of the top challenges organizations face when trying to take a Machine Learning model into production are:</p><h1 class="lr ls jw bm lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo ga" id="cb48">Machine Learning Demands Heterogeneity</h1><p class="pw-post-body-paragraph kt ku jw kv b kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm mt lo lp lq je ga" id="2c8f">End-to-end ML applications often comprise of components written in different <strong class="kv jx">programming languages</strong>. Depending on the use case, a data scientist might choose Python, R, Scala, or another language to build one model, then another language for a second model. Within a given language, there are numerous frameworks and toolkits available. TensorFlow, PyTorch, and Scikit–learn all work with Python, but each is tuned for specific types of operations, and each outputs a slightly different type of model. For data pre-processing, JVM-based systems such as Apache Spark are often preferred, due to static typing in the language for better support for parallel execution. Such heterogeneous codebases are often hard to keep consistent.</p><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="828e">The <strong class="kv jx">variety</strong> of frameworks and toolkits enable the data scientist to choose a language and tool that best suits the problem at hand. However, each new tool and language they choose must be enabled and handled by IT teams. Containerization technologies, such as Docker, can solve incompatibility and portability challenges introduced by the multitude of tools. However, automatic dependency checking, error checking, testing, and build tools will not be able to tackle problems across the language barrier.</p><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="0c50"><strong class="kv jx">Reproducibility</strong> is also a challenge in these scenarios. Data Scientists may build many versions of the model each using different programming languages, libraries or different versions of the same library. It is difficult to track these dependencies manually. To solve these challenges, an ML lifecycle tool is required that can automatically track and log these dependencies during the training phase as configuration as code and later bundle them along with the trained model in a ready-to-deploy artifact.</p><h1 class="lr ls jw bm lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo ga" id="056c">ML Deployments Are Not Standalone</h1><p class="pw-post-body-paragraph kt ku jw kv b kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm mt lo lp lq je ga" id="2c61">Machine learning model deployments are not self-contained solutions. They are usually either embedded or integrated into business applications. Deploying a Model by wrapping it as a <strong class="kv jx">REST API </strong>is the easiest solution to integrate with business applications in a language-agnostic way.</p><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="ac6e">This approach aligns well with microservices architecture and enables to individually update or scale the machine learning model component. Creating REST APIs is easy as most of the frameworks provide the capability out of the box, but some times Models need to be deployed as <strong class="kv jx">gRPC APIs </strong>for efficient network usage and better performance, especially when the size of inputs (images, videos, text) is large.</p><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="89b4">As <strong class="kv jx">edge devices </strong>(mobiles, IoT, etc) are becoming more and more powerful in terms of computing and storage, there is an increasing trend of deploying and running models directly on these devices. However, models in this case still need to be <strong class="kv jx">optimized for CPU and memory usage</strong>. In most cases, models are embedded in the applications running on these devices, so the challenges of <strong class="kv jx">runtime compatibility and portability </strong>arise. The challenge here is to take a model trained in any programming language/library and optimize and export it to match the runtime language and version of the edge devices.</p><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="038e">A widely used approach other than REST/gRPC APIs for integrating disparate components is the use of messaging systems. An ability to package and deploy a model that can integrate with <strong class="kv jx">messaging systems </strong>can avoid a lot of boilerplate code and ease deployments.</p><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="f853">In some cases, project constraints and compliance requirements dictate deployment needs, for example, converting a model trained using a python library and deploying it to Azure <strong class="kv jx">confidential computing </strong>environment which supports a C++ runtime.</p><h1 class="lr ls jw bm lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo ga" id="c246">Intricacies of ML Model Definition</h1><p class="pw-post-body-paragraph kt ku jw kv b kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm mt lo lp lq je ga" id="43d2">What is a Machine Learning model? Is it only the model parameters obtained after training (e.g., the weights of a logistic regression model)? Does it need to also include feature transformations which are important for the model to work correctly? Many libraries combine feature transformations and the actual ML model in a single abstraction often referred to as <strong class="kv jx">ML pipelines</strong>. From a systems perspective, the model can be considered a ‘black-box’ with defined inputs and outputs or it could be considered as a combination of operations with known semantics. A model could be a combination of models (e.g., <strong class="kv jx">ensembles </strong>where models from different languages or libraries are combined, or where an output of one model is the input to another model).</p><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="85b4">Service-Oriented Architecture and <strong class="kv jx">microservices </strong>have moved applications from monolithic code to more composable and manageable pieces of components. Machine learning is even more composable as its building blocks are more granular and disparate. In real-world applications, ML models are deployed and managed as a single unit or as multiple components each managed and updated individually.</p><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="29b1">For example, a Public Relations firm looking to identify news and reports critical of one of its customers might use the following pipeline:</p><ul class=""><li class="mu mv jw kv b kw kx la lb le mw li mx lm my lq mz na nb nc ga" id="0c83">Extract text from a stream of scanned documents with an Optical Character Recognition (OCR) model</li><li class="mu mv jw kv b kw nd la ne le nf li ng lm nh lq mz na nb nc ga" id="38af">Identify the language of that text with a language-identification model</li><li class="mu mv jw kv b kw nd la ne le nf li ng lm nh lq mz na nb nc ga" id="35e5">Translate non-English text to English</li><li class="mu mv jw kv b kw nd la ne le nf li ng lm nh lq mz na nb nc ga" id="11c3">Prepare the text for sentiment</li></ul><figure class="nj nk nl nm gx jn gl gm paragraph-image"><div class="jo jp do jq ce jr" role="button" tabindex="0"><div class="gl gm ni"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*jN7O47fcQ73gg2L-yLiadQ.png 640w, https://miro.medium.com/max/720/1*jN7O47fcQ73gg2L-yLiadQ.png 720w, https://miro.medium.com/max/750/1*jN7O47fcQ73gg2L-yLiadQ.png 750w, https://miro.medium.com/max/786/1*jN7O47fcQ73gg2L-yLiadQ.png 786w, https://miro.medium.com/max/828/1*jN7O47fcQ73gg2L-yLiadQ.png 828w, https://miro.medium.com/max/1100/1*jN7O47fcQ73gg2L-yLiadQ.png 1100w, https://miro.medium.com/max/1400/1*jN7O47fcQ73gg2L-yLiadQ.png 1400w"/><img alt="" class="ce js jt c" height="417" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="nn bl gn gl gm no np bm b bn bo cn"><strong class="bm nq">Figure:</strong> An ML pipeline that extracts text from scanned documents and analyzes the sentiment of OCR’ed text.</figcaption></figure><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="47ea">In each case, a model might be developed using a different set of languages and tools.</p><h1 class="lr ls jw bm lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo ga" id="f609">Testing &amp; Validation Struggles</h1><p class="pw-post-body-paragraph kt ku jw kv b kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm mt lo lp lq je ga" id="10e7">Models evolve continuously as data changes, methods improve or software dependencies change. Every time such a change occurs, model performance must be re-validated. These validations introduce several challenges and pitfalls:</p><ul class=""><li class="mu mv jw kv b kw kx la lb le mw li mx lm my lq mz na nb nc ga" id="2c77">The models must be evaluated using the same test and validation datasets to be able to compare the performance of different ML models.</li><li class="mu mv jw kv b kw nd la ne le nf li ng lm nh lq mz na nb nc ga" id="3344">The same code for evaluating metrics must be used throughout time and across different models to be able to guarantee comparability.</li><li class="mu mv jw kv b kw nd la ne le nf li ng lm nh lq mz na nb nc ga" id="963b">Updates to test/validation datasets or code require the different ML models (including old and new) to be re-evaluated in order to be comparable. This introduces unique challenges in CI/CD pipelines complicating the process of automatically training and deploying newer versions of ML models in production.</li><li class="mu mv jw kv b kw nd la ne le nf li ng lm nh lq mz na nb nc ga" id="7a99">The improvement in a new model may come at a cost e.g., longer prediction times. To identify such impacts, benchmark tests and load/stress tests must be part of the validation and decision-making process.</li></ul><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="baa5">Apart from the validation of models in offline tests, assessing the performance of models in production is crucial. This is discussed in the deployment strategy and monitoring sections.</p><h1 class="lr ls jw bm lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo ga" id="7d64">Convoluted Release Strategies</h1><p class="pw-post-body-paragraph kt ku jw kv b kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm mt lo lp lq je ga" id="f21b">Like any software application being deployed today, the release of ML models is not in any way less complex. ML models need to be updated more frequently than regular software applications.</p><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="201b">Release strategy and deployment infrastructure for ML must consider the heterogeneity factor and the fact that a Model may include multiple components each built using a different programming language or ML framework. Each of these components may need to be updated or rolled back independently or as a single unit. Also, to see the best ROI from ML models, it is important to be able to deploy models as fast as possible and repeatedly.</p><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="22b9">Launching a new model in “shadow mode” (i.e., capture the inputs and predictions in production without actually serving those predictions) helps catch operational problems, smoke test the model and analyze results without any impact to end-users.</p><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="a182"><strong class="kv jx">A/B or bandit test</strong> modes are required to compare model performance in a production environment and analyze impacts on user experience and ROI. However, this could be quite challenging in cases where the feedback loops are long and indirect. The capability to accept inputs and random inspection from humans should also be considered. This is particularly required in scenarios where less labeled data is available and where the cost of errors is too high.</p><figure class="nj nk nl nm gx jn gl gm paragraph-image"><div class="gl gm nr"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 524px" srcset="https://miro.medium.com/max/640/1*d8pjusAWUB20yUEjcGS6Sg.png 640w, https://miro.medium.com/max/720/1*d8pjusAWUB20yUEjcGS6Sg.png 720w, https://miro.medium.com/max/750/1*d8pjusAWUB20yUEjcGS6Sg.png 750w, https://miro.medium.com/max/786/1*d8pjusAWUB20yUEjcGS6Sg.png 786w, https://miro.medium.com/max/828/1*d8pjusAWUB20yUEjcGS6Sg.png 828w, https://miro.medium.com/max/1100/1*d8pjusAWUB20yUEjcGS6Sg.png 1100w, https://miro.medium.com/max/1048/1*d8pjusAWUB20yUEjcGS6Sg.png 1048w"/><img alt="" class="ce js jt c" height="376" loading="lazy" role="presentation" width="524"/></picture></div><figcaption class="nn bl gn gl gm no np bm b bn bo cn"><strong class="bm nq">Figure:</strong> Example Runtime Model Graph</figcaption></figure><h1 class="lr ls jw bm lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo ga" id="f16f">CI/CD: A Gaggle of Disparate Pipelines</h1><p class="pw-post-body-paragraph kt ku jw kv b kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm mt lo lp lq je ga" id="b27c">It has become very common for software developers to use Continuous Integration (CI) and Continuous Deployment (CD) tools. CI/CD tools are helping development teams to push rapid and accurate updates to production. Other benefits of CI/CD tools are reliability, reproducibility, velocity, security and version control.</p><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="ae0c">Most CI/CD tools support the well-known software development workflows which include build, test and deploy steps. Machine learning workflows exhibit unique characteristics that are not observed in traditional development workflows.</p><figure class="nj nk nl nm gx jn gl gm paragraph-image"><div class="jo jp do jq ce jr" role="button" tabindex="0"><div class="gl gm ns"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*8ca86DbTggtP-LxUggiAPQ.jpeg 640w, https://miro.medium.com/max/720/1*8ca86DbTggtP-LxUggiAPQ.jpeg 720w, https://miro.medium.com/max/750/1*8ca86DbTggtP-LxUggiAPQ.jpeg 750w, https://miro.medium.com/max/786/1*8ca86DbTggtP-LxUggiAPQ.jpeg 786w, https://miro.medium.com/max/828/1*8ca86DbTggtP-LxUggiAPQ.jpeg 828w, https://miro.medium.com/max/1100/1*8ca86DbTggtP-LxUggiAPQ.jpeg 1100w, https://miro.medium.com/max/1400/1*8ca86DbTggtP-LxUggiAPQ.jpeg 1400w"/><img alt="" class="ce js jt c" height="394" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="nn bl gn gl gm no np bm b bn bo cn"><strong class="bm nq">Figure:</strong> Machine Learning Workflow</figcaption></figure><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="ddd6">The most significant difference between traditional applications and ML models is the fact that the primary input is not just code. Rather, there are two equally important input components: code and data. One must apply versioning to both these inputs to achieve reproducibility and auditability. One must also monitor both the data and code for any changes and then automatically trigger the workflow. This may not be trivial, especially given the intricacies of data management. As discussed already under Model Validation, a change in test/validation data will need retraining and/or re-validating the Models. When building ML workflows, one must consider this need.</p><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="e11a">Hardware and software dependencies for traditional application development are usually homogenous. In the case of machine learning, each stage of the workflow may demand specific hardware and software components. Training stages are typically long and intensive on computing. Some workloads may demand the availability of hardware accelerators such as GPUs. CI/CD tools used for ML workflows should be capable of provisioning such dependencies on demand.</p><h1 class="lr ls jw bm lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo ga" id="55fd">ML without Monitoring is a Nightmare</h1><p class="pw-post-body-paragraph kt ku jw kv b kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm mt lo lp lq je ga" id="d5fe">Monitoring tools are constantly evolving to support today’s cloud-native distributed containerized applications. Monitoring is now being replaced with Observability and includes logs, traces, and metrics. The tools, however, still need to evolve further to support machine learning.</p><h2 class="nt ls jw bm lt nu nv nw lx nx ny nz mb le oa ob mf li oc od mj lm oe of mn og ga" id="7133">Increased Scope</h2><p class="pw-post-body-paragraph kt ku jw kv b kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm mt lo lp lq je ga" id="5a56">The scope of monitoring has been increasing to support more stakeholders. Most monitoring tools today not just help DevOps to proactively monitor systems but also help developers to debug and understand issues.</p><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="9ac0">In the case of machine learning, the scope of monitoring further increases to include Data Scientists and Business Owners. Monitoring tools need to help these new stakeholders know how well a model is performing in production and to understand its output. The metrics to monitor, the information to log, the compliance needs, and the audit requirements for machine learning are very different from regular applications. More on this in the sections below.</p><h2 class="nt ls jw bm lt nu nv nw lx nx ny nz mb le oa ob mf li oc od mj lm oe of mn og ga" id="5feb">Increased Complexity</h2><p class="pw-post-body-paragraph kt ku jw kv b kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm mt lo lp lq je ga" id="9ca5">As discussed in the above sections, ML is heterogeneous. Standardizing and baking in monitoring into the deployment pipeline is easy for a single programming language or framework. Doing this to support different programming languages and frameworks is time-consuming, error-prone and complex. Given the fact that ML models can be comprised of other models and components, it is very important to be able to trace these components individually and be able to narrow down issues to one of them. Employing microservices architecture with containers, service meshes and immutable infrastructure are great techniques to deal with and standardize deployments of complex ML models with heterogeneity. However, these tools are not easy to configure and maintain. Specialized teams are required to put these into practice.</p><h2 class="nt ls jw bm lt nu nv nw lx nx ny nz mb le oa ob mf li oc od mj lm oe of mn og ga" id="070c">Hardware Accelerators</h2><p class="pw-post-body-paragraph kt ku jw kv b kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm mt lo lp lq je ga" id="7df1">ML frameworks like TensorFlow, PyTorch, Theanos and more support use of Graphical Processing Units (GPUs) to improve the speed of computation. Google provides Tensorflow Processing Units (TPUs) which provide acceleration over and above GPUs. Intel recently released Neural Network Processors (NNP) for deep learning training and inference at scale.</p><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="04c8">These hardware accelerators are expensive and their usage should be monitored and optimized for cost-effectiveness. Most monitoring tools don’t provide this monitoring capability out of the box and require setup of additional tools/plugins.</p><h2 class="nt ls jw bm lt nu nv nw lx nx ny nz mb le oa ob mf li oc od mj lm oe of mn og ga" id="d454">ML Specific Metrics</h2><p class="pw-post-body-paragraph kt ku jw kv b kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm mt lo lp lq je ga" id="e34c">ML performance is far more multidimensional, integrating several different kinds of metrics.</p><ul class=""><li class="mu mv jw kv b kw kx la lb le mw li mx lm my lq mz na nb nc ga" id="60f7"><strong class="kv jx">Accuracy: </strong>how well is the model making predictions, determined from feedback and actuals received</li><li class="mu mv jw kv b kw nd la ne le nf li ng lm nh lq mz na nb nc ga" id="f696"><strong class="kv jx">Data Drift: </strong>drift computation of training &amp; actual feedback disparity (output), drift computation of training/runtime data disparity (input) and drift computation of correlation across features</li><li class="mu mv jw kv b kw nd la ne le nf li ng lm nh lq mz na nb nc ga" id="d4ea"><strong class="kv jx">Bias: </strong>computation of Input vs. Output (train vs. actual)</li><li class="mu mv jw kv b kw nd la ne le nf li ng lm nh lq mz na nb nc ga" id="8ca4"><strong class="kv jx">Anomaly: </strong>detection and logging all inputs with anomalies</li><li class="mu mv jw kv b kw nd la ne le nf li ng lm nh lq mz na nb nc ga" id="503b"><strong class="kv jx">Explainability: </strong>of top features per prediction</li></ul><h1 class="lr ls jw bm lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo ga" id="8261">Conclusion</h1><p class="pw-post-body-paragraph kt ku jw kv b kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm mt lo lp lq je ga" id="c4f8">Machine learning is still in its early stages. Both software and hardware components are constantly evolving to meet the current demands of ML. They are evolving at a faster rate but the tools required to operationalize them are yet to catch up.</p><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="6774">Docker/Kubernetes and micro-services architecture can be employed to solve the heterogeneity and infrastructure challenges. Comet and MLflow are trying to address experiment versioning and reproducibility problems. Cloud platform services such as SageMaker, Azure ML, Google AI cater to the scalable deployments. Existing tools can partly solve some problems individually. Bringing all these tools together to operationalize ML is the biggest challenge today. Most times, this may not be practical especially in enterprises and regulated industries.</p><p class="pw-post-body-paragraph kt ku jw kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq je ga" id="1d8b">As existing tools grow and as new tools get introduced to solve these challenges, one should consider the fact that the data science community is largely comprised of individuals from academic and research background. The tools that operationalize ML must be simple enough to be usable by such users and at the same time be able to address the intricate challenges of ML.</p></div></div></section></div></div></article>